{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNLM 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "xs = np.array([[1,2,3]])\n",
    "print(xs.shape)\n",
    "print(xs[:,0])\n",
    "print(xs[:,0].shape)\n",
    "W = np.arange(28).reshape(7,4)\n",
    "print(W[0])\n",
    "print(W[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "a = a.reshape(-1,1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "a = a[:, np.newaxis]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "a = a[np.newaxis, :]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],\n",
    "              [3,4]])\n",
    "# b = 3\n",
    "# b = np.array([2,2])\n",
    "b = np.array([[2],[2]])\n",
    "a+b   # (2,2) + (2,1) => (2,2) + (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dx = np.arange(21).reshape(3,7)\n",
    "mask = np.ones((3,))\n",
    "print(mask)\n",
    "print(mask.shape)\n",
    "print(mask.reshape(3,1).shape)\n",
    "print(mask[:, np.newaxis].shape)\n",
    "\n",
    "dx * mask[:, np.newaxis]  # (3,7)*(3,1) => (3,7)*(3,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.time_layers import *\n",
    "\n",
    "D=4\n",
    "H=3\n",
    "rnn_Wx = np.arange(D*H).reshape(D,H)\n",
    "rnn_Wh = np.arange(H*H).reshape(H,H)\n",
    "rnn_b = np.arange(H)\n",
    "\n",
    "rnn = RNN(rnn_Wx, rnn_Wh, rnn_b)\n",
    "print(rnn.params[0])\n",
    "print(rnn.params[1])\n",
    "print(rnn.params[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (1,2)\n",
    "print(type(a))\n",
    "b = 1,2\n",
    "print(type(b))\n",
    "a,b = (1,2)\n",
    "print(type(a))\n",
    "\n",
    "def foo():\n",
    "    return 1,2\n",
    "\n",
    "a,b = foo()\n",
    "print(a,b)\n",
    "\n",
    "def foo(a,b):\n",
    "    print(a,b)\n",
    "    \n",
    "foo(*(1,2))\n",
    "\n",
    "\n",
    "a = np.arange(3*4).reshape(3,4)\n",
    "b = np.random.rand(*a.shape) # 명시적인 튜플 언패킹\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AAA:\n",
    "    def __init__(self):\n",
    "        self.x = 10\n",
    "        y = 20\n",
    "        print('__init__()', self)\n",
    "        \n",
    "    def foo(self):\n",
    "        print(self.x)\n",
    "#         print(y)\n",
    "        \n",
    "a = AAA()\n",
    "print(a)\n",
    "a.foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x - x.max(axis=1, keepdims=True)\n",
    "        x = np.exp(x)\n",
    "        x /= x.sum(axis=1, keepdims=True)\n",
    "    elif x.ndim == 1:\n",
    "        x = x - np.max(x)\n",
    "        x = np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "    return x\n",
    "\n",
    "xs = np.random.randn(3,7)\n",
    "ts = np.array([1,2,3])\n",
    "ys = softmax(xs)\n",
    "print(ys)\n",
    "print(np.sum(ys, axis=1))\n",
    "\n",
    "print(ys[np.arange(1 * 3), ts])\n",
    "ls = np.log(ys[np.arange(1 * 3), ts])\n",
    "print(ls)\n",
    "loss = -np.sum(ls)\n",
    "print(loss)\n",
    "loss /= 3\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array([1,1,1])\n",
    "print(mask)\n",
    "print(mask.shape)\n",
    "print(mask.reshape(-1,1).shape)\n",
    "print(mask[:, np.newaxis].shape)\n",
    "print(mask[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = np.arange(21).reshape(3,7)\n",
    "print(dx)\n",
    "mask = np.array([0,1,0])\n",
    "dx *= mask[:, np.newaxis]\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reversed(range(3)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.time_layers import *\n",
    "\n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNLM의 학습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(929589,)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 27 24 39 26 40 41 42 26 43\n",
      " 32 44 45 46 24 47 26 27 28 29 48 49 41 42 50 51 52 53 54 55 35 36 37 42\n",
      " 56 57 58 59 24 35 60 42 61 62 63 64 65 66 67 68 69 70 35 71 72 42 73 74\n",
      " 75 35 46 42]\n",
      "<class 'dict'>\n",
      "10000\n",
      "<unk>\n",
      "aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter <eos> pierre <unk> N years old will join the board as a nonexecutive director nov. N <eos> mr. <unk> is chairman of <unk> n.v. the dutch publishing group <eos> rudolph <unk> N years old and former chairman of consolidated gold fields plc was named a nonexecutive director of this british industrial conglomerate <eos> a form of asbestos once used to make kent cigarette filters has caused a high percentage of cancer deaths among a group of \n",
      "4\n",
      "말뭉치 크기: 929589, 어휘 수: 10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "print(corpus.shape)\n",
    "print(corpus[:100])\n",
    "print(type(word_to_id))\n",
    "print(len(word_to_id))\n",
    "print(id_to_word[26])\n",
    "\n",
    "for i in range(100):\n",
    "    print(id_to_word[corpus[i]], end=' ')\n",
    "print()\n",
    "\n",
    "print(word_to_id['centrust'])\n",
    "\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "print('말뭉치 크기: %d, 어휘 수: %d' % (len(corpus), vocab_size))\n",
    "print(len(word_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 | 퍼플렉서티 381.20\n",
      "| 에폭 2 | 퍼플렉서티 253.18\n",
      "| 에폭 3 | 퍼플렉서티 221.54\n",
      "| 에폭 4 | 퍼플렉서티 213.72\n",
      "| 에폭 5 | 퍼플렉서티 204.30\n",
      "| 에폭 6 | 퍼플렉서티 201.27\n",
      "| 에폭 7 | 퍼플렉서티 197.19\n",
      "| 에폭 8 | 퍼플렉서티 195.92\n",
      "| 에폭 9 | 퍼플렉서티 190.93\n",
      "| 에폭 10 | 퍼플렉서티 192.85\n",
      "| 에폭 11 | 퍼플렉서티 189.02\n",
      "| 에폭 12 | 퍼플렉서티 192.22\n",
      "| 에폭 13 | 퍼플렉서티 190.68\n",
      "| 에폭 14 | 퍼플렉서티 191.20\n",
      "| 에폭 15 | 퍼플렉서티 190.42\n",
      "| 에폭 16 | 퍼플렉서티 186.12\n",
      "| 에폭 17 | 퍼플렉서티 184.48\n",
      "| 에폭 18 | 퍼플렉서티 181.32\n",
      "| 에폭 19 | 퍼플렉서티 182.51\n",
      "| 에폭 20 | 퍼플렉서티 182.95\n",
      "| 에폭 21 | 퍼플렉서티 181.28\n",
      "| 에폭 22 | 퍼플렉서티 177.17\n",
      "| 에폭 23 | 퍼플렉서티 174.91\n",
      "| 에폭 24 | 퍼플렉서티 175.54\n",
      "| 에폭 25 | 퍼플렉서티 173.16\n",
      "| 에폭 26 | 퍼플렉서티 172.82\n",
      "| 에폭 27 | 퍼플렉서티 167.53\n",
      "| 에폭 28 | 퍼플렉서티 166.15\n",
      "| 에폭 29 | 퍼플렉서티 164.06\n",
      "| 에폭 30 | 퍼플렉서티 157.03\n",
      "| 에폭 31 | 퍼플렉서티 157.72\n",
      "| 에폭 32 | 퍼플렉서티 152.77\n",
      "| 에폭 33 | 퍼플렉서티 153.17\n",
      "| 에폭 34 | 퍼플렉서티 146.34\n",
      "| 에폭 35 | 퍼플렉서티 145.01\n",
      "| 에폭 36 | 퍼플렉서티 139.85\n",
      "| 에폭 37 | 퍼플렉서티 136.53\n",
      "| 에폭 38 | 퍼플렉서티 134.42\n",
      "| 에폭 39 | 퍼플렉서티 127.24\n",
      "| 에폭 40 | 퍼플렉서티 121.77\n",
      "| 에폭 41 | 퍼플렉서티 122.39\n",
      "| 에폭 42 | 퍼플렉서티 115.57\n",
      "| 에폭 43 | 퍼플렉서티 109.36\n",
      "| 에폭 44 | 퍼플렉서티 105.92\n",
      "| 에폭 45 | 퍼플렉서티 102.86\n",
      "| 에폭 46 | 퍼플렉서티 100.28\n",
      "| 에폭 47 | 퍼플렉서티 93.75\n",
      "| 에폭 48 | 퍼플렉서티 91.20\n",
      "| 에폭 49 | 퍼플렉서티 86.97\n",
      "| 에폭 50 | 퍼플렉서티 83.39\n",
      "| 에폭 51 | 퍼플렉서티 78.86\n",
      "| 에폭 52 | 퍼플렉서티 77.14\n",
      "| 에폭 53 | 퍼플렉서티 72.48\n",
      "| 에폭 54 | 퍼플렉서티 70.00\n",
      "| 에폭 55 | 퍼플렉서티 67.81\n",
      "| 에폭 56 | 퍼플렉서티 62.35\n",
      "| 에폭 57 | 퍼플렉서티 59.66\n",
      "| 에폭 58 | 퍼플렉서티 57.55\n",
      "| 에폭 59 | 퍼플렉서티 54.53\n",
      "| 에폭 60 | 퍼플렉서티 51.03\n",
      "| 에폭 61 | 퍼플렉서티 49.26\n",
      "| 에폭 62 | 퍼플렉서티 46.56\n",
      "| 에폭 63 | 퍼플렉서티 42.44\n",
      "| 에폭 64 | 퍼플렉서티 40.17\n",
      "| 에폭 65 | 퍼플렉서티 40.08\n",
      "| 에폭 66 | 퍼플렉서티 36.96\n",
      "| 에폭 67 | 퍼플렉서티 35.61\n",
      "| 에폭 68 | 퍼플렉서티 32.02\n",
      "| 에폭 69 | 퍼플렉서티 29.99\n",
      "| 에폭 70 | 퍼플렉서티 29.51\n",
      "| 에폭 71 | 퍼플렉서티 28.38\n",
      "| 에폭 72 | 퍼플렉서티 25.90\n",
      "| 에폭 73 | 퍼플렉서티 25.49\n",
      "| 에폭 74 | 퍼플렉서티 23.84\n",
      "| 에폭 75 | 퍼플렉서티 22.69\n",
      "| 에폭 76 | 퍼플렉서티 21.12\n",
      "| 에폭 77 | 퍼플렉서티 20.78\n",
      "| 에폭 78 | 퍼플렉서티 19.67\n",
      "| 에폭 79 | 퍼플렉서티 18.23\n",
      "| 에폭 80 | 퍼플렉서티 17.29\n",
      "| 에폭 81 | 퍼플렉서티 15.86\n",
      "| 에폭 82 | 퍼플렉서티 15.65\n",
      "| 에폭 83 | 퍼플렉서티 13.97\n",
      "| 에폭 84 | 퍼플렉서티 14.10\n",
      "| 에폭 85 | 퍼플렉서티 13.82\n",
      "| 에폭 86 | 퍼플렉서티 12.43\n",
      "| 에폭 87 | 퍼플렉서티 12.03\n",
      "| 에폭 88 | 퍼플렉서티 11.16\n",
      "| 에폭 89 | 퍼플렉서티 10.46\n",
      "| 에폭 90 | 퍼플렉서티 10.17\n",
      "| 에폭 91 | 퍼플렉서티 9.72\n",
      "| 에폭 92 | 퍼플렉서티 9.42\n",
      "| 에폭 93 | 퍼플렉서티 8.43\n",
      "| 에폭 94 | 퍼플렉서티 8.26\n",
      "| 에폭 95 | 퍼플렉서티 7.97\n",
      "| 에폭 96 | 퍼플렉서티 7.46\n",
      "| 에폭 97 | 퍼플렉서티 7.15\n",
      "| 에폭 98 | 퍼플렉서티 6.60\n",
      "| 에폭 99 | 퍼플렉서티 6.60\n",
      "| 에폭 100 | 퍼플렉서티 6.06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "\n",
    "# 1. (N,T) 로 입력\n",
    "# 2. (N,T) => (N,T,D)  임베딩층 통과 시\n",
    "# 3. (N,H)(H,H)+(N,D)(D,H)+(H,) => (N,H) => (N,T,H)  RNN 층 통과 시\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5     # Truncated BPTT가 한 번에 펼치는 시간 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기(전체 중 1000개만)\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "# print('말뭉치 크기: %d, 어휘 수: %d' % (corpus_size, vocab_size))\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "# print(vocab_size)\n",
    "\n",
    "xs = corpus[:-1]  # 입력\n",
    "ts = corpus[1:]   # 출력(정답 레이블)\n",
    "data_size = len(xs)\n",
    "# print('말뭉치 크기: %d, 어휘 수: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 학습 시 사용하는 변수\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "# 미니배치의 각 샘플의 읽기 시작 위치를 계산\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # 미니배치 취득\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "\n",
    "        # 기울기를 구하여 매개변수 갱신\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # 에폭마다 퍼플렉서티 평가\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| 에폭 %d | 퍼플렉서티 %.2f'\n",
    "          % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n",
    "\n",
    "# 그래프 그리기\n",
    "x = np.arange(len(ppl_list))\n",
    "plt.plot(x, ppl_list, label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('perplexity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].W[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNLM의 Trainer 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5  # RNN을 펼치는 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000  # 테스트 데이터셋을 작게 설정\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "xs = corpus[:-1]  # 입력\n",
    "ts = corpus[1:]  # 출력（정답 레이블）\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size)\n",
    "trainer.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "out = np.zeros((2,3,4))\n",
    "embed_W = np.arange(28).reshape(7,4)\n",
    "\n",
    "idx = [0,3]\n",
    "out[:,0,:] = embed_W[idx]\n",
    "idx = [1,4]\n",
    "out[:,1,:] = embed_W[idx]\n",
    "idx = [2,1]\n",
    "out[:,2,:] = embed_W[idx]\n",
    "\n",
    "out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "xs = np.arange(18).reshape(2,3,3)\n",
    "print(xs)\n",
    "rx  = xs.reshape(2*3,-1)\n",
    "print(rx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
