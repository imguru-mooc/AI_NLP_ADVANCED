{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩 계층 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "[0 1 2 3 4 1 5]\n",
      "[1 2 3 4 1 5 6]\n",
      "(1, 3)\n",
      "[[0 1 2]]\n",
      "(1, 3)\n",
      "[[1 2 3]]\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]\n",
      " [16 17 18 19]\n",
      " [20 21 22 23]\n",
      " [24 25 26 27]]\n",
      "[0 1 2 3]\n",
      "[[0 1 2 3]]\n",
      "(1, 3, 4)\n",
      "[[[ 0.  1.  2.  3.]\n",
      "  [ 4.  5.  6.  7.]\n",
      "  [ 8.  9. 10. 11.]]]\n",
      "[[[ 0.  1.  2.  3.]\n",
      "  [ 4.  5.  6.  7.]\n",
      "  [ 8.  9. 10. 11.]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.np import *  # import numpy as np (or import cupy as np)\n",
    "from common.layers import *\n",
    "from common.time_layers import *\n",
    "\n",
    "corpus = np.array([0,1,2,3,4,1,5,6])\n",
    "print(corpus)\n",
    "xs = corpus[:-1]  # 입력\n",
    "print(xs)\n",
    "ts = corpus[1:]   # 출력(정답 레이블)\n",
    "print(ts)\n",
    "\n",
    "batch_size = 1\n",
    "time_size = 3\n",
    "batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "print(batch_x.shape)\n",
    "\n",
    "batch_x[0] = xs[:time_size]\n",
    "print(batch_x)\n",
    "\n",
    "batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "print(batch_t.shape)\n",
    "\n",
    "batch_t[0] = ts[:time_size]\n",
    "print(batch_t)\n",
    "\n",
    "embed_W = np.arange(28).reshape(7,4)\n",
    "print(embed_W)\n",
    "\n",
    "print(embed_W[0])   # (4,)\n",
    "print(embed_W[[0]]) # (1,4)\n",
    "embed = TimeEmbedding(embed_W)\n",
    "out = embed.forward(batch_x)\n",
    "print(out.shape)\n",
    "print(out)\n",
    "\n",
    "out = np.empty((1, 3, 4), dtype='f')\n",
    "\n",
    "# out[:, 0, :] = embed_W[batch_x[:, 0]]\n",
    "# out[:, 1, :] = embed_W[batch_x[:, 1]]\n",
    "# out[:, 2, :] = embed_W[batch_x[:, 2]]\n",
    "for t in range(3):\n",
    "    out[:, t, :] = embed_W[batch_x[:, t]]  # embed_W[[0]]\n",
    "    \n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.np import *  # import numpy as np (or import cupy as np)\n",
    "from common.layers import *\n",
    "from common.functions import sigmoid\n",
    "\n",
    "\n",
    "class MyRNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b\n",
    "        h_next = t #np.tanh(t)\n",
    "\n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "\n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "\n",
    "        dt = dh_next #dh_next * (1 - h_next ** 2)\n",
    "        \n",
    "        db = np.sum(dt, axis=0)\n",
    "        print('db=', db)\n",
    "        dWh = np.dot(h_prev.T, dt)\n",
    "        print('dWh=', dWh)\n",
    "        dh_prev = np.dot(dt, Wh.T)\n",
    "        print('dh_prev=', dh_prev)\n",
    "        dWx = np.dot(x.T, dt)\n",
    "        print('dWx=' , dWx)\n",
    "        dx = np.dot(dt, Wx.T)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time RNN 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.dh = None, None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = MyRNN(*self.params)\n",
    "            self.h = layer.forward(xs[:, t, :], self.h)\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = Wx.shape\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:, t, :] + dh)\n",
    "            dxs[:, t, :] = dx\n",
    "\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "\n",
    "        print('self.grads=',self.grads)\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEmbedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.idx = None\n",
    "\n",
    "    def forward(self, idx):\n",
    "        W, = self.params\n",
    "        self.idx = idx\n",
    "        out = W[idx]\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dW, = self.grads\n",
    "        dW[...] = 0\n",
    "        np.add.at(dW, self.idx, dout)\n",
    "        print(\"dW=\", dW)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTimeEmbedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.layers = None\n",
    "        self.W = W\n",
    "\n",
    "    def forward(self, xs):\n",
    "        N, T = xs.shape\n",
    "        V, D = self.W.shape\n",
    "\n",
    "        out = np.empty((N, T, D), dtype='f')\n",
    "        self.layers = []\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = MyEmbedding(self.W)\n",
    "            out[:, t, :] = layer.forward(xs[:, t])\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, T, D = dout.shape\n",
    "\n",
    "        grad = 0\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            layer.backward(dout[:, t, :])\n",
    "            grad += layer.grads[0]\n",
    "\n",
    "        self.grads[0][...] = grad\n",
    "        print('self.grads=',self.grads)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Rnn 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.np import *  # import numpy as np (or import cupy as np)\n",
    "from common.layers import *\n",
    "from common.time_layers import *\n",
    "\n",
    "corpus = np.array([0,1,2,3,4,1,5,6])\n",
    "# print(copus)\n",
    "xs = corpus[:-1]  # 입력\n",
    "# print(xs)\n",
    "ts = corpus[1:]   # 출력(정답 레이블)\n",
    "# print(ts)\n",
    "\n",
    "batch_size = 1\n",
    "time_size = 3\n",
    "batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "# print(batch_x.shape)\n",
    "\n",
    "batch_x[0] = xs[:3]\n",
    "# print(batch_x)\n",
    "\n",
    "batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "# print(batch_t.shape)\n",
    "\n",
    "batch_t[0] = ts[:3]\n",
    "# print(batch_t)\n",
    "\n",
    "embed_W = np.arange(28).reshape(7,4)\n",
    "# print(embed_W)\n",
    "\n",
    "embed = MyTimeEmbedding(embed_W)\n",
    "out = embed.forward(batch_x)\n",
    "print(out)\n",
    "\n",
    "rnn_Wx = np.ones((4,3), dtype='f')\n",
    "print(rnn_Wx)\n",
    "rnn_Wh = np.ones((3,3), dtype='f')\n",
    "print(rnn_Wh)\n",
    "rnn_b = np.full((3,),3, dtype='f')\n",
    "print(rnn_b)\n",
    "rnn = MyTimeRNN(rnn_Wx, rnn_Wh, rnn_b)\n",
    "out = rnn.forward(out)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dout = np.array([[[1,1,1],\n",
    "                  [2,2,2],\n",
    "                  [3,3,3]]])\n",
    "dxs = rnn.backward(dout)\n",
    "print(dxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed.backward(dxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimeSoftfmax 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  9 17]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ts = np.array([1,2,3])\n",
    "ys = np.arange(21).reshape(3,7)\n",
    "print(ys[np.arange(1 * 3), ts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.74656412 0.16041545 0.06387572 0.80466656 0.59972826 0.69049783\n",
      "  0.95573689]\n",
      " [0.70060085 0.80877414 0.38109442 0.70527564 0.14985207 0.03574291\n",
      "  0.53616769]\n",
      " [0.71295126 0.90294095 0.87696362 0.36800266 0.91564519 0.51965462\n",
      "  0.91707076]]\n",
      "[[ 0.74656412 -0.83958455  0.06387572  0.80466656  0.59972826  0.69049783\n",
      "   0.95573689]\n",
      " [ 0.70060085  0.80877414 -0.61890558  0.70527564  0.14985207  0.03574291\n",
      "   0.53616769]\n",
      " [ 0.71295126  0.90294095  0.87696362 -0.63199734  0.91564519  0.51965462\n",
      "   0.91707076]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ts = np.array([1,2,3])\n",
    "ys = np.random.rand(3,7)\n",
    "print(ys)\n",
    "dx = ys\n",
    "dx[np.arange(1 * 3), ts] -= 1\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(np.newaxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1]\n",
      "[[1]\n",
      " [0]\n",
      " [1]]\n",
      "[[1]\n",
      " [0]\n",
      " [1]]\n",
      "[[ 0.   -0.3   0.03  0.    0.    2.66  0.  ]\n",
      " [ 0.   -0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.   -0.3   0.03  0.    0.    2.66  0.  ]]\n"
     ]
    }
   ],
   "source": [
    "mask = np.array([1,0,1])\n",
    "dx = np.array([[0,-0.3, 0.03, 0, 0, 2.66, 0 ],\n",
    "               [0,-0.3, 0.03, 0, 0, 2.66, 0 ],\n",
    "               [0,-0.3, 0.03, 0, 0, 2.66, 0 ]])\n",
    "dx *= mask[:, np.newaxis] \n",
    "print(mask)\n",
    "print(mask.reshape(3,1))\n",
    "print(mask[:, np.newaxis])\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
