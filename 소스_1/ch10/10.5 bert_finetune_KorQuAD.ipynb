{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U --user numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12607,
     "status": "ok",
     "timestamp": 1594010753269,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "B9WLyWEWgdDR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import wget\n",
    "\n",
    "MAX_LEN = 512\n",
    "EPOCHS = 3\n",
    "VERBOSE = 2\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1594010762115,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "68HVB3dYgi0w"
   },
   "outputs": [],
   "source": [
    "DATA_OUT_PATH = './data_out/KOR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1594010763471,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "zvoswBdyglTQ"
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, string, string_1, string_2):\n",
    "    # loss \n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history[string_1])\n",
    "    plt.plot(history.history[string_2])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, string_1, string_2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)\n",
    "np.random.seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 65,
     "referenced_widgets": [
      "bc7f3c579a324f77811bdd6ad6dd7dc0",
      "e31de13423d743e68d6c451d23c93cdf",
      "f8f80478dfca4894ac1ff8c2a082f734",
      "3be3c9704e934fb5a3d5847749d398ce",
      "2c0ecef646d44a0580cacefa5c3fd9f2",
      "1fde406732df4b5b90b7701dc7e4981e",
      "f58154a65f974e04bcf8af24b2884fdd",
      "a7d4d0c48cda4abdb106a6bcfb24359e"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1594010812799,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "HDI_cm3sgm6N",
    "outputId": "33078a97-0007-428b-9439-b67bd53cd994"
   },
   "outputs": [],
   "source": [
    "# Save the slow pretrained tokenizer\n",
    "slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", lowercase=False)\n",
    "save_path = \"bert-base-multilingual-cased/\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "slow_tokenizer.save_pretrained(save_path)\n",
    "\n",
    "# Load the fast tokenizer from saved file\n",
    "tokenizer = BertWordPieceTokenizer(\"bert-base-multilingual-cased/vocab.txt\", lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1750,
     "status": "ok",
     "timestamp": 1594010820826,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "an5cGi-GgpG4",
    "outputId": "c7753a24-f338-4a6d-8701-f78753f9b718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://korquad.github.io/dataset/KorQuAD_v1.0_train.json\n",
      "38535168/38527475 [==============================] - 1s 0us/step\n",
      "38543360/38527475 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "train_data_url = \"https://korquad.github.io/dataset/KorQuAD_v1.0_train.json\"\n",
    "train_path = keras.utils.get_file(\"train.json\", train_data_url)\n",
    "eval_data_url = \"https://korquad.github.io/dataset/KorQuAD_v1.0_dev.json\"\n",
    "eval_path = keras.utils.get_file(\"eval.json\", eval_data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% [                                                       ]   0 / 625\r",
      "100% [.......................................................] 625 / 625"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./bert-base-multilingual-cased//bert-base-multilingual-cased-config (1).json'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wget.download('https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json', out='./bert-base-multilingual-cased/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename('./bert-base-multilingual-cased/bert-base-multilingual-cased-config.json', './bert-base-multilingual-cased/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [.........................................] 1083389348 / 1083389348"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./bert-base-multilingual-cased//bert-base-multilingual-cased-tf_model.h5'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wget.download('https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-tf_model.h5', out='./bert-base-multilingual-cased/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename('./bert-base-multilingual-cased/bert-base-multilingual-cased-tf_model.h5', './bert-base-multilingual-cased/tf_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['밑바닥', '부터', '시작하는', '딥러닝']\n",
      "밑바닥 부터 시작하는 딥러닝\n"
     ]
    }
   ],
   "source": [
    "a = \"\"\"밑바닥     부터    시작하는 \n",
    "\n",
    "\n",
    "딥러닝\"\"\"\n",
    "print(str(a).split())\n",
    "a = \" \".join(str(a).split())\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 99893,
     "status": "ok",
     "timestamp": 1594011009085,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "PkuK7N_ngrMd",
    "outputId": "48275df3-52de-4623-dfc3-db6be9a54dfa"
   },
   "outputs": [],
   "source": [
    "class SquadExample:\n",
    "    def __init__(self, question, context, start_char_idx, answer_text):\n",
    "        self.question = question\n",
    "        self.context = context\n",
    "        self.start_char_idx = start_char_idx\n",
    "        self.answer_text = answer_text\n",
    "        self.skip = False\n",
    "\n",
    "    def preprocess(self):\n",
    "        context = self.context\n",
    "        question = self.question\n",
    "        answer_text = self.answer_text\n",
    "        start_char_idx = self.start_char_idx\n",
    "\n",
    "#         print('context=',context)\n",
    "#         print('question=',question)\n",
    "#         print('answer_text=',answer_text)\n",
    "#         print('start_char_idx=',start_char_idx)\n",
    "        # Clean context, answer and question\n",
    "        context = \" \".join(str(context).split())\n",
    "        question = \" \".join(str(question).split())\n",
    "        answer = \" \".join(str(answer_text).split())\n",
    "\n",
    "        # Find end character index of answer in context\n",
    "        end_char_idx = start_char_idx + len(answer)\n",
    "#         print('end_char_idx=',end_char_idx)\n",
    "        if end_char_idx >= len(context):\n",
    "            self.skip = True\n",
    "            return\n",
    "\n",
    "        # Mark the character indexes in context that are in answer\n",
    "        is_char_in_ans = [0] * len(context)\n",
    "        for idx in range(start_char_idx, end_char_idx):\n",
    "            is_char_in_ans[idx] = 1\n",
    "        \n",
    "#         print(\"is_char_in_ans = \", is_char_in_ans)\n",
    "\n",
    "        # Tokenize context\n",
    "        tokenized_context = tokenizer.encode(context)\n",
    "\n",
    "# [ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]        \n",
    "#         print(\"tokenized_context = \", tokenized_context)\n",
    "#         print('tokenized_context.ids=', tokenized_context.ids)\n",
    "#         print('tokenized_context.type_ids=', tokenized_context.type_ids)\n",
    "#         print('tokenized_context.tokens=', tokenized_context.tokens)\n",
    "#         print('tokenized_context.offsets=',tokenized_context.offsets)\n",
    "#         print('tokenized_context.attention_mask=', tokenized_context.attention_mask)\n",
    "#         print('tokenized_context.special_tokens_mask=', tokenized_context.special_tokens_mask)\n",
    "        \n",
    "        # Find tokens that were created from answer characters\n",
    "        ans_token_idx = []\n",
    "        for idx, (start, end) in enumerate(tokenized_context.offsets):\n",
    "            if sum(is_char_in_ans[start:end]) > 0:\n",
    "                ans_token_idx.append(idx)\n",
    "                \n",
    "#         print(\"ans_token_idx=\", ans_token_idx)\n",
    "\n",
    "        if len(ans_token_idx) == 0:\n",
    "            self.skip = True\n",
    "            return\n",
    "\n",
    "        # Find start and end token index for tokens from answer\n",
    "        start_token_idx = ans_token_idx[0]\n",
    "        end_token_idx = ans_token_idx[-1]\n",
    "        \n",
    "#         print('start_token_idx=', start_token_idx)\n",
    "#         print('end_token_idx=', end_token_idx)\n",
    "\n",
    "        # Tokenize question\n",
    "        tokenized_question = tokenizer.encode(question)\n",
    "\n",
    "        # Create inputs\n",
    "\n",
    "#         print('tokenized_question.ids=', tokenized_question.ids)\n",
    "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
    "#         print('input_ids=', input_ids)\n",
    "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(\n",
    "            tokenized_question.ids[1:]\n",
    "        )\n",
    "#         print('token_type_ids=', token_type_ids)\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "#         print('attention_mask=', attention_mask)\n",
    "\n",
    "#         print(\"len(input_ids)=\", len(input_ids))\n",
    "        # Pad and create attention masks.\n",
    "        # Skip if truncation is needed\n",
    "        padding_length = MAX_LEN - len(input_ids)\n",
    "        if padding_length > 0:  # pad\n",
    "            input_ids = input_ids + ([0] * padding_length)\n",
    "            attention_mask = attention_mask + ([0] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        elif padding_length < 0:  # skip\n",
    "            self.skip = True\n",
    "            return\n",
    "\n",
    "#         print('input_ids=', input_ids)\n",
    "#         print('token_type_ids=', token_type_ids)\n",
    "#         print('attention_mask=', attention_mask)\n",
    "        self.input_ids = input_ids\n",
    "        self.token_type_ids = token_type_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.start_token_idx = start_token_idx\n",
    "        self.end_token_idx = end_token_idx\n",
    "        self.context_token_to_char = tokenized_context.offsets\n",
    "\n",
    "\n",
    "def create_squad_examples(raw_data):\n",
    "    squad_examples = []\n",
    "    for item in raw_data[\"data\"]:\n",
    "        for para in item[\"paragraphs\"]:\n",
    "            context = para[\"context\"]\n",
    "#             print('context = ' , context)\n",
    "            for qa in para[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "#                 print('question = ' , question)\n",
    "                \n",
    "                answer_text = qa[\"answers\"][0][\"text\"]\n",
    "#                 print('answer_text = ', answer_text)\n",
    "                start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
    "#                 print('start_char_idx = ', start_char_idx)\n",
    "                squad_eg = SquadExample(\n",
    "                    question, context, start_char_idx, answer_text\n",
    "                )\n",
    "                squad_eg.preprocess()\n",
    "                squad_examples.append(squad_eg)\n",
    "#                 break\n",
    "#             break\n",
    "#         break\n",
    "    return squad_examples\n",
    "\n",
    "\n",
    "def create_inputs_targets(squad_examples):\n",
    "    dataset_dict = {\n",
    "        \"input_ids\": [],\n",
    "        \"token_type_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"start_token_idx\": [],\n",
    "        \"end_token_idx\": [],\n",
    "    }\n",
    "    for item in squad_examples:\n",
    "        if item.skip == False:\n",
    "            for key in dataset_dict:\n",
    "                dataset_dict[key].append(getattr(item, key))\n",
    "#             print(dataset_dict)\n",
    "#             break\n",
    "#         break\n",
    "            \n",
    "    for key in dataset_dict:\n",
    "        dataset_dict[key] = np.array(dataset_dict[key])\n",
    "\n",
    "    x = [\n",
    "        dataset_dict[\"input_ids\"],\n",
    "        dataset_dict[\"token_type_ids\"],\n",
    "        dataset_dict[\"attention_mask\"],\n",
    "    ]\n",
    "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jikim\\.keras\\datasets\\train.json\n"
     ]
    }
   ],
   "source": [
    "print(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "60407\n",
      "[101, 16221, 10954, 9318, 78136, 70162, 11018, 8905, 119351, 10459, 9901, 89108, 15184, 10622, 62849, 9642, 11664, 8924, 8996, 24974, 10530, 9246, 32158, 10739, 8973, 26737, 35756, 9448, 36210, 11261, 9960, 12424, 90387, 8907, 79544, 55670, 10622, 9511, 26737, 11018, 9153, 10622, 8854, 40410, 119, 9638, 9485, 12310, 9318, 78136, 70162, 11018, 16347, 27056, 9387, 9088, 119267, 11467, 9407, 16617, 15891, 54918, 9056, 100, 9414, 65649, 10739, 17342, 9686, 58931, 11882, 9489, 89292, 10530, 8843, 118813, 51491, 9272, 97146, 12605, 26444, 119394, 100929, 11513, 9248, 49742, 9901, 89108, 15184, 10459, 9491, 31720, 10530, 8896, 105197, 12490, 11664, 16139, 119, 19789, 9901, 46766, 12424, 9519, 52015, 77884, 20308, 10459, 9706, 119455, 11261, 9901, 12692, 74293, 14279, 8900, 30842, 119110, 24989, 10739, 9568, 16323, 12178, 9344, 26444, 118979, 10459, 8907, 79544, 55670, 130, 35465, 10622, 9116, 11664, 8938, 10892, 8848, 52859, 9322, 119118, 41850, 117, 9638, 97403, 9638, 118815, 14523, 17206, 10530, 9901, 89108, 15184, 10459, 9425, 55670, 11467, 9511, 29935, 18623, 9638, 9652, 52951, 10530, 9678, 40032, 10739, 17342, 12092, 58088, 8978, 119266, 119185, 12692, 60362, 30050, 9637, 71013, 14843, 9565, 80795, 39218, 119, 9565, 46874, 9157, 24989, 20626, 9678, 79599, 28467, 35979, 21555, 9665, 33797, 9664, 80579, 13767, 8870, 92383, 9059, 119064, 11102, 9670, 25387, 14801, 9946, 11261, 16439, 9489, 10459, 11287, 9321, 30858, 13441, 27487, 45021, 9344, 26444, 118979, 10459, 9957, 100420, 25242, 79544, 55670, 9678, 79599, 58088, 74141, 21371, 9359, 9460, 11506, 119, 8924, 82838, 8907, 79544, 55670, 76512, 10622, 16221, 87188, 10533, 27056, 92210, 9901, 46766, 12424, 9731, 15891, 119424, 35466, 122, 119110, 35963, 9512, 9109, 10530, 9694, 24989, 12490, 119, 19789, 9652, 52951, 10459, 9591, 17138, 11882, 58248, 17889, 9638, 9425, 55670, 113, 122, 119110, 13890, 114, 9633, 9901, 12692, 74293, 74125, 9568, 16323, 14863, 11489, 9568, 16323, 14843, 9901, 15184, 30005, 18382, 9691, 29455, 35506, 74519, 117, 9489, 53914, 11018, 9638, 35866, 12965, 12508, 32815, 49137, 119, 50342, 9757, 25486, 10892, 125, 10954, 9321, 10739, 9706, 33305, 56528, 9113, 100929, 118790, 11489, 9568, 16323, 49953, 9659, 25486, 12092, 9638, 35866, 12965, 119210, 28578, 117, 18347, 10530, 110589, 9328, 18622, 29208, 9251, 27303, 119, 8924, 64932, 17889, 9238, 86933, 18622, 12638, 9328, 65649, 12178, 9011, 118783, 61592, 83200, 9591, 17138, 12453, 9847, 20309, 10739, 48387, 35979, 9731, 15891, 12178, 9121, 9367, 16323, 11102, 9485, 90295, 9356, 118726, 41850, 117, 8924, 56710, 9318, 119023, 9420, 119446, 10739, 9638, 8889, 10622, 9649, 14153, 9954, 27487, 63783, 11287, 23969, 9637, 118634, 12092, 11506, 119, 102, 9318, 78136, 70162, 11018, 8905, 119351, 10459, 9901, 89108, 101825, 9642, 11664, 9294, 119137, 10622, 9511, 11664, 13764, 9965, 11018, 11287, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "33\n",
      "35\n",
      "[(0, 0), (0, 4), (4, 5), (6, 7), (7, 8), (8, 9), (9, 10), (11, 12), (12, 13), (13, 14), (15, 16), (16, 18), (18, 19), (19, 20), (21, 23), (24, 25), (25, 26), (27, 28), (29, 30), (30, 31), (31, 32), (33, 34), (34, 35), (35, 36), (37, 38), (38, 39), (40, 42), (43, 44), (44, 45), (45, 46), (47, 48), (48, 49), (50, 53), (54, 55), (55, 56), (56, 57), (57, 58), (59, 60), (60, 61), (61, 62), (63, 64), (64, 65), (66, 67), (67, 69), (69, 70), (71, 72), (73, 74), (74, 75), (76, 77), (77, 78), (78, 79), (79, 80), (81, 85), (85, 87), (88, 89), (90, 91), (91, 92), (92, 94), (95, 96), (96, 97), (97, 98), (98, 100), (101, 102), (103, 105), (106, 107), (107, 108), (108, 109), (109, 110), (111, 112), (112, 113), (113, 114), (115, 116), (116, 117), (117, 118), (119, 120), (120, 121), (121, 124), (125, 126), (126, 127), (127, 128), (128, 129), (129, 130), (130, 132), (132, 133), (134, 135), (135, 137), (138, 139), (139, 141), (141, 142), (142, 143), (144, 145), (145, 146), (146, 147), (148, 149), (149, 150), (150, 152), (152, 153), (154, 156), (156, 157), (158, 160), (161, 162), (162, 164), (164, 165), (166, 167), (167, 168), (168, 169), (169, 170), (170, 171), (172, 173), (173, 174), (174, 175), (176, 177), (177, 178), (179, 181), (181, 182), (183, 184), (184, 185), (185, 186), (186, 187), (187, 188), (189, 190), (190, 191), (191, 193), (194, 195), (195, 196), (196, 197), (197, 198), (199, 200), (200, 201), (201, 202), (203, 204), (204, 205), (205, 206), (207, 208), (208, 209), (210, 211), (211, 212), (213, 214), (214, 216), (217, 218), (218, 219), (219, 221), (221, 222), (223, 224), (224, 226), (227, 228), (228, 229), (229, 230), (231, 233), (233, 234), (235, 236), (236, 238), (238, 239), (239, 240), (241, 242), (242, 243), (243, 245), (246, 247), (247, 248), (248, 249), (250, 251), (252, 253), (253, 254), (254, 255), (256, 257), (257, 258), (258, 259), (259, 260), (260, 261), (262, 265), (266, 267), (267, 268), (268, 269), (269, 270), (270, 272), (273, 275), (276, 277), (277, 278), (278, 279), (280, 281), (281, 283), (284, 286), (286, 287), (288, 289), (289, 291), (292, 293), (293, 294), (294, 295), (296, 297), (297, 299), (300, 302), (302, 304), (305, 307), (308, 309), (309, 311), (312, 313), (313, 314), (315, 317), (318, 319), (319, 321), (322, 323), (323, 324), (324, 325), (326, 327), (327, 328), (328, 329), (330, 331), (331, 332), (332, 333), (334, 335), (335, 336), (336, 337), (338, 339), (339, 340), (340, 341), (342, 344), (345, 348), (349, 350), (350, 351), (351, 352), (352, 353), (354, 355), (355, 356), (356, 357), (357, 358), (358, 359), (360, 361), (361, 363), (364, 367), (368, 370), (371, 373), (374, 375), (376, 377), (378, 380), (380, 381), (382, 383), (383, 385), (386, 387), (387, 388), (388, 389), (390, 392), (392, 393), (394, 398), (398, 401), (402, 404), (404, 406), (407, 409), (410, 411), (411, 413), (413, 414), (415, 416), (416, 417), (417, 418), (418, 420), (421, 422), (422, 423), (423, 425), (426, 427), (428, 429), (429, 430), (431, 432), (432, 433), (433, 435), (435, 436), (437, 439), (440, 441), (441, 442), (442, 443), (444, 445), (445, 446), (446, 447), (448, 451), (452, 454), (455, 456), (457, 458), (458, 459), (459, 460), (460, 461), (461, 462), (462, 463), (463, 464), (464, 465), (466, 467), (467, 468), (469, 471), (471, 473), (474, 475), (475, 476), (476, 477), (477, 479), (480, 481), (481, 482), (482, 483), (484, 485), (485, 486), (486, 487), (487, 489), (490, 491), (491, 492), (492, 493), (493, 496), (496, 497), (498, 499), (499, 501), (501, 502), (503, 504), (504, 505), (505, 506), (506, 507), (507, 509), (510, 513), (513, 514), (515, 517), (518, 519), (519, 520), (520, 521), (522, 523), (523, 524), (525, 526), (526, 527), (528, 529), (529, 530), (531, 533), (534, 535), (535, 537), (537, 538), (538, 540), (541, 542), (542, 543), (543, 546), (547, 548), (548, 549), (549, 550), (551, 552), (552, 553), (553, 554), (554, 555), (555, 557), (557, 558), (559, 561), (561, 562), (563, 566), (567, 568), (568, 569), (569, 571), (572, 573), (573, 575), (575, 576), (577, 578), (579, 582), (583, 585), (586, 587), (587, 588), (588, 589), (589, 590), (591, 592), (592, 593), (593, 595), (596, 597), (597, 598), (598, 600), (600, 602), (603, 604), (604, 605), (605, 607), (608, 609), (609, 610), (610, 611), (611, 612), (612, 614), (615, 616), (616, 617), (617, 619), (620, 621), (622, 623), (623, 624), (624, 625), (626, 627), (627, 629), (630, 631), (631, 632), (632, 634), (634, 635), (636, 637), (637, 638), (639, 640), (640, 641), (642, 643), (643, 644), (644, 645), (646, 647), (648, 649), (649, 650), (651, 652), (652, 653), (654, 655), (656, 658), (659, 661), (661, 662), (663, 665), (666, 667), (667, 668), (668, 669), (670, 672), (672, 673), (0, 0)]\n"
     ]
    }
   ],
   "source": [
    "with open(train_path) as f:\n",
    "    raw_train_data = json.load(f)\n",
    "\n",
    "print(type(raw_train_data))    \n",
    "    \n",
    "with open(eval_path) as f:\n",
    "    raw_eval_data = json.load(f)\n",
    "\n",
    "#         self.input_ids = input_ids\n",
    "#         self.token_type_ids = token_type_ids\n",
    "#         self.attention_mask = attention_mask\n",
    "#         self.start_token_idx = start_token_idx\n",
    "#         self.end_token_idx = end_token_idx\n",
    "#         self.context_token_to_char = tokenized_context.offsets\n",
    "\n",
    "train_squad_examples = create_squad_examples(raw_train_data)\n",
    "# print(len(train_squad_examples))\n",
    "# print(train_squad_examples[0].input_ids)\n",
    "# print(train_squad_examples[0].token_type_ids)\n",
    "# print(train_squad_examples[0].attention_mask)\n",
    "# print(train_squad_examples[0].start_token_idx)\n",
    "# print(train_squad_examples[0].end_token_idx)\n",
    "# print(train_squad_examples[0].context_token_to_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60407 training points created.\n",
      "5774 evaluation points created.\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
    "print(f\"{len(train_squad_examples)} training points created.\")\n",
    "# print(x_train[0][0])\n",
    "\n",
    "eval_squad_examples = create_squad_examples(raw_eval_data)\n",
    "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
    "print(f\"{len(eval_squad_examples)} evaluation points created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡 ( 1악장 ) 을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다. 바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?\n",
      "[(0, 0), (0, 4), (4, 5), (6, 7), (7, 8), (8, 9), (9, 10), (11, 12), (12, 13), (13, 14), (15, 16), (16, 18), (18, 19), (19, 20), (21, 23), (24, 25), (25, 26), (27, 28), (29, 30), (30, 31), (31, 32), (33, 34), (34, 35), (35, 36), (37, 38), (38, 39), (40, 42), (43, 44), (44, 45), (45, 46), (47, 48), (48, 49), (50, 53), (54, 55), (55, 56), (56, 57), (57, 58), (59, 60), (60, 61), (61, 62), (63, 64), (64, 65), (66, 67), (67, 69), (69, 70), (71, 72), (73, 74), (74, 75), (76, 77), (77, 78), (78, 79), (79, 80), (81, 85), (85, 87), (88, 89), (90, 91), (91, 92), (92, 94), (95, 96), (96, 97), (97, 98), (98, 100), (101, 102), (103, 104), (104, 105), (105, 106), (106, 107), (108, 109), (109, 110), (110, 111), (112, 113), (113, 114), (114, 115), (116, 117), (117, 118), (118, 121), (122, 123), (123, 124), (124, 125), (125, 126), (126, 127), (127, 129), (129, 130), (131, 132), (132, 134), (135, 136), (136, 138), (138, 139), (139, 140), (141, 142), (142, 143), (143, 144), (145, 146), (146, 147), (147, 149), (149, 150), (151, 153), (153, 154), (155, 157), (158, 159), (159, 161), (161, 162), (163, 164), (164, 165), (165, 166), (166, 167), (167, 168), (169, 170), (170, 171), (171, 172), (173, 174), (174, 175), (176, 178), (178, 179), (180, 181), (181, 182), (182, 183), (183, 184), (184, 185), (186, 187), (187, 188), (188, 190), (191, 192), (192, 193), (193, 194), (194, 195), (196, 197), (197, 198), (198, 199), (200, 201), (201, 202), (202, 203), (204, 205), (205, 206), (207, 208), (208, 209), (210, 211), (211, 213), (214, 215), (215, 216), (216, 218), (218, 219), (220, 221), (221, 223), (224, 225), (225, 226), (226, 227), (228, 230), (230, 231), (232, 233), (233, 235), (235, 236), (236, 237), (238, 239), (239, 240), (240, 242), (243, 244), (244, 245), (245, 246), (247, 248), (249, 250), (250, 251), (251, 252), (253, 254), (254, 255), (255, 256), (256, 257), (257, 258), (259, 262), (263, 264), (264, 265), (265, 266), (266, 267), (267, 269), (270, 272), (273, 274), (274, 275), (275, 276), (277, 278), (278, 280), (281, 283), (283, 284), (285, 286), (286, 288), (289, 290), (290, 291), (291, 292), (293, 294), (294, 296), (297, 299), (299, 301), (302, 304), (305, 306), (306, 308), (309, 310), (310, 311), (312, 314), (315, 316), (316, 318), (319, 320), (320, 321), (321, 322), (323, 324), (324, 325), (325, 326), (327, 328), (328, 329), (329, 330), (331, 332), (332, 333), (333, 334), (335, 336), (336, 337), (337, 338), (339, 341), (342, 345), (346, 347), (347, 348), (348, 349), (349, 350), (351, 352), (352, 353), (353, 354), (354, 355), (355, 356), (357, 358), (358, 360), (361, 364), (365, 367), (368, 370), (371, 372), (373, 374), (375, 377), (377, 378), (379, 380), (380, 382), (383, 384), (384, 385), (385, 386), (387, 389), (389, 390), (391, 395), (395, 398), (399, 401), (401, 403), (404, 406), (407, 408), (408, 410), (410, 411), (412, 413), (413, 414), (414, 415), (415, 417), (418, 419), (419, 420), (420, 422), (423, 424), (425, 426), (426, 427), (428, 429), (429, 430), (430, 432), (432, 433), (434, 436), (437, 438), (438, 439), (439, 440), (441, 442), (442, 443), (443, 444), (445, 448), (449, 451), (452, 453), (454, 455), (455, 456), (457, 458), (459, 460), (460, 461), (461, 462), (463, 464), (465, 466), (467, 468), (468, 469), (470, 472), (472, 474), (475, 476), (476, 477), (477, 478), (478, 480), (481, 482), (482, 483), (483, 484), (485, 486), (486, 487), (487, 488), (488, 490), (491, 492), (492, 493), (493, 494), (494, 497), (497, 498), (499, 500), (500, 502), (502, 503), (504, 505), (505, 506), (506, 507), (507, 508), (508, 510), (511, 514), (514, 515), (516, 518), (519, 520), (520, 521), (521, 522), (523, 524), (524, 525), (526, 527), (527, 528), (529, 530), (530, 531), (532, 534), (535, 536), (536, 538), (538, 539), (539, 541), (542, 543), (543, 544), (544, 547), (548, 549), (549, 550), (550, 551), (552, 553), (553, 554), (554, 555), (555, 556), (556, 558), (558, 559), (560, 562), (562, 563), (564, 567), (568, 569), (569, 570), (570, 572), (573, 574), (574, 576), (576, 577), (578, 579), (580, 583), (584, 586), (587, 588), (588, 589), (589, 590), (590, 591), (592, 593), (593, 594), (594, 596), (597, 598), (598, 599), (599, 601), (601, 603), (604, 605), (605, 606), (606, 608), (609, 610), (610, 611), (611, 612), (612, 613), (613, 615), (616, 617), (617, 618), (618, 620), (621, 622), (623, 624), (624, 625), (625, 626), (627, 628), (628, 630), (631, 632), (632, 633), (633, 635), (635, 636), (637, 638), (638, 639), (640, 641), (641, 642), (643, 644), (644, 645), (645, 646), (647, 648), (649, 650), (650, 651), (652, 653), (653, 654), (655, 656), (657, 659), (660, 662), (662, 663), (664, 666), (667, 668), (668, 669), (669, 670), (671, 673), (673, 674), (675, 676), (676, 677), (677, 678), (678, 679), (680, 681), (681, 682), (682, 683), (684, 686), (686, 687), (688, 689), (689, 690), (690, 692), (693, 694), (695, 696), (696, 697), (698, 699), (699, 700), (700, 701), (701, 702), (702, 703), (703, 704), (0, 0)]\n",
      "254 256\n",
      "419 424\n",
      "악장을 쓴\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "\n",
    "# print(x_train[0][0])\n",
    "context = tokenizer.decode(x_train[0][idx])\n",
    "print(context)\n",
    "\n",
    "tokenized_context = tokenizer.encode(context)\n",
    "offset = tokenized_context.offsets\n",
    "print(offset)\n",
    "\n",
    "start = y_train[0][idx]\n",
    "end = y_train[1][idx]\n",
    "print(start, end)\n",
    "\n",
    "start = offset[start][0]\n",
    "end = offset[end][1]\n",
    "\n",
    "print(start, end)\n",
    "print(context[start:end])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 690,
     "status": "ok",
     "timestamp": 1594011009787,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "mIjk3_XeguBj"
   },
   "outputs": [],
   "source": [
    "class TFBERTQuestionAnswering(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBERTQuestionAnswering, self).__init__()\n",
    "        \n",
    "        self.encoder = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.start_logit = tf.keras.layers.Dense(num_class, name=\"start_logit\", use_bias=False) #(N,T,D)(D,1)=(N,T,1)\n",
    "        self.end_logit = tf.keras.layers.Dense(num_class, name=\"end_logit\", use_bias=False)\n",
    "        self.flatten = tf.keras.layers.Flatten() \n",
    "        self.softmax = tf.keras.layers.Activation(tf.keras.activations.softmax)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_ids, token_type_ids, attention_mask = inputs\n",
    "        embedding = self.encoder(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "#         print(embedding)\n",
    "#         print(embedding.last_hidden_state)\n",
    "#         print(embedding[0])\n",
    "        embedding = embedding[0]\n",
    "        print(embedding.shape)   # (1,512,768)\n",
    "        start_logits = self.start_logit(embedding)\n",
    "        print(start_logits.shape) # (1,512,1)\n",
    "        start_logits = self.flatten(start_logits)\n",
    "        print(start_logits.shape) # (1,512)\n",
    "        \n",
    "        end_logits = self.end_logit(embedding)\n",
    "        end_logits = self.flatten(end_logits)\n",
    "        \n",
    "        start_probs = self.softmax(start_logits)\n",
    "        end_probs = self.softmax(end_logits)\n",
    "    \n",
    "        return start_probs, end_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ./bert-base-multilingual-cased/ were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at ./bert-base-multilingual-cased/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512)\n",
      "(1, 512, 768)\n",
      "(1, 512, 1)\n",
      "(1, 512)\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "korquad_model = TFBERTQuestionAnswering(model_name='./bert-base-multilingual-cased/',dir_path='bert_ckpt', num_class=1)\n",
    "inputs = [x_train[0][0:1] , x_train[1][0:1], x_train[2][0:1]]\n",
    "print(inputs[0].shape)\n",
    "start_probs, end_probs = korquad_model(inputs)\n",
    "print(np.argmax(start_probs.numpy))\n",
    "print(np.argmax(end_probs.numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11135,
     "status": "ok",
     "timestamp": 1594011020239,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "k4t_2T7vgwOu",
    "outputId": "fd7dcb5d-bf36-496c-b53d-53e89962360a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ./bert-base-multilingual-cased/ were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at ./bert-base-multilingual-cased/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "korquad_model = TFBERTQuestionAnswering(model_name='./bert-base-multilingual-cased/',dir_path='bert_ckpt', num_class=1)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1594011103474,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "YZtVFA3PgyL0"
   },
   "outputs": [],
   "source": [
    "def normalized_answer(s):    \n",
    "    def remove_(text):\n",
    "        ''' 불필요한 기호 제거 '''\n",
    "        text = re.sub(\"'\", \" \", text)\n",
    "        text = re.sub('\"', \" \", text)\n",
    "        text = re.sub('《', \" \", text)\n",
    "        text = re.sub('》', \" \", text)\n",
    "        text = re.sub('<', \" \", text)\n",
    "        text = re.sub('>', \" \", text) \n",
    "        text = re.sub('〈', \" \", text)\n",
    "        text = re.sub('〉', \" \", text)   \n",
    "        text = re.sub(\"\\(\", \" \", text)\n",
    "        text = re.sub(\"\\)\", \" \", text)\n",
    "        text = re.sub(\"‘\", \" \", text)\n",
    "        text = re.sub(\"’\", \" \", text)      \n",
    "        return text\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_punc(lower(remove_(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1594011104061,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "rVTh1qKng1p8"
   },
   "outputs": [],
   "source": [
    "class ExactMatch(keras.callbacks.Callback):\n",
    "    def __init__(self, x_eval, y_eval):\n",
    "        self.x_eval = x_eval\n",
    "        self.y_eval = y_eval\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
    "        count = 0\n",
    "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
    "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
    "            squad_eg = eval_examples_no_skip[idx]\n",
    "            offsets = squad_eg.context_token_to_char\n",
    "            start = np.argmax(start)\n",
    "            end = np.argmax(end)\n",
    "            if start >= len(offsets):\n",
    "                continue\n",
    "            pred_char_start = offsets[start][0]\n",
    "            if end < len(offsets):\n",
    "                pred_char_end = offsets[end][1]\n",
    "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
    "            else:\n",
    "                pred_ans = squad_eg.context[pred_char_start:]\n",
    "\n",
    "            normalized_pred_ans = normalized_answer(pred_ans)\n",
    "            normalized_true_ans = normalized_answer(squad_eg.answer_text)\n",
    "            if normalized_pred_ans in normalized_true_ans:\n",
    "                count += 1\n",
    "        acc = count / len(self.y_eval[0])\n",
    "        print(f\"\\nepoch={epoch+1}, exact match score={acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 399,
     "status": "ok",
     "timestamp": 1594011104303,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "sTgvtk0og4Ow"
   },
   "outputs": [],
   "source": [
    "exact_match_callback = ExactMatch(x_eval, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1594011105561,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "7EuBYS58g6QZ"
   },
   "outputs": [],
   "source": [
    "korquad_model.compile(optimizer=optimizer, loss=[loss, loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1594011106252,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "ZehxFPSrg8Q2",
    "outputId": "6a33f8a1-84d0-48c4-ac1e-5843daf1f2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_out/KOR\\tf2_bert_korquad -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tf2_bert_korquad\"\n",
    "\n",
    "checkpoint_path = os.path.join(DATA_OUT_PATH, model_name, 'weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18126376,
     "status": "ok",
     "timestamp": 1594029233934,
     "user": {
      "displayName": "ChangWook Jun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjljUh9LMLCM8kMgWLaX2xHiw2Cej8KoaOlkKxE=s64",
      "userId": "00685987924881157185"
     },
     "user_tz": -540
    },
    "id": "2ljuajCLmyws",
    "outputId": "e89526e8-e795-48df-eead-1a00b28005bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "(None, 512, 768)\n",
      "(None, 512, 1)\n",
      "(None, 512)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "(None, 512, 768)\n",
      "(None, 512, 1)\n",
      "(None, 512)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-9f552f3a31a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = korquad_model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# For demonstration, 3 epochs are recommended\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVERBOSE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = korquad_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,  # For demonstration, 3 epochs are recommended\n",
    "    verbose=VERBOSE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[exact_match_callback, cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QxaigHy2m4JB"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss', 'output_1_loss', 'output_2_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "korquad_model.save_weights('data_out/KOR/tf2_bert_korquad/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "korquad_model.load_weights('data_out/KOR/tf2_bert_korquad/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "korquad_model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(korquad_model.history,'loss', 'output_1_loss', 'output_2_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 predict 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "korquad_model.load_weights('data_out/KOR/tf2_bert_korquad/weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 지문 찾아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국 육군사관학교로 임명을 획득하여 자신의 어린 시절을 군사 경력의 야망으로. 그 경력은 헤이그의 학문적 경연이 암시하려고 한것보다 더욱 극적이었으며 그는 1947년 310의 동기병에서 217번째 사관으로서 졸업하였다. 22세의 소위로 헤이그는 처음에 캔자스 주 포트라일리에서 정통 제병 연합부대로, 그러고나서 켄터키 주 포트녹스에 있는 기갑 훈련소로 갔다. 그후에 그는 제1 기병 사단으로 선임되고 그러고나서 일본에서 점령군의 임무와 기력이 없는 훈련을 하였다. 그는 1950년 5월 한번 자신의 사령관 알론조 폭스 장군의 딸 퍼트리샤 앤토이넷 폭스와 결혼하여 슬하 3명의 자식을 두었다. 알렉산더 헤이그가 미국 육군사관학교로 임명받은 해는 언제인가?\n"
     ]
    }
   ],
   "source": [
    "idx = 20\n",
    "print(tokenizer.decode(x_eval[0][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   101   9022  21876  28911  36240  72085  11489  92360  18784   9957\n",
      "  12692  17022   9491  66540  11102   8896  73969   9954  10003   9973\n",
      "  10739  78136  11018  10825  10954  23545   9626  17360  12945  20595\n",
      "  46599  11261   9644  52859   9999 118813  13374  31956 106320   9485\n",
      "  58931  10622   8910  12945   8885  28143  10459   9538  89292  11467\n",
      "    100    119   8924   8885  28143  10892   9973  10739  78136  10459\n",
      "   9953  25934  14801   8885  25486  10739   9526  14040  35506  26737\n",
      "  11664   9954 118627  80001  99958   8925  14801  10739  52476  17889\n",
      "  11113  10954  23993  10459   9095  12310  73380  11489  21651  48506\n",
      "   9405  20595  11467  12424  45004  12609    119  10306  65443   9448\n",
      "  92454   9973  10739  78136  11018  62849  10530   9793  13764  12605\n",
      "   9689   9928  15184  17342  18392  46766  12424   9670  43022   9672\n",
      "  73380   9568  33188  14646  37601    117   8924  30873  11664  16439\n",
      "  12424   9807  21876  21039   9689   9928  15184 118742  12605  10530\n",
      "  13767   8932 118610  10004 101440  22333  11261   8852  11903    119\n",
      "   8924  31531  10530  17889   9672  10759   8932  73380   9405  24989\n",
      "  11467   9428  36240  29208   8924  30873  11664  16439  12424  23130\n",
      "  11489   9668  44220  46741   9644  32537  12638   8932  61964  40364\n",
      "  10004 101440  10622  28750    119  17889  10811  10954  17162   9954\n",
      "  35465  31956   9405  44220  20595   9524  42769  20626   9929  12605\n",
      "   9657  46741   9133   9913  15184  12692 119035   9534  26444  10739\n",
      "  82881   9929  12605  12638   8881 119439  13374   9479  35506    124\n",
      "  45441   9651  48132   9102  17706    119    102   9524 118872  21386\n",
      "  54141   9973  10739  78136  11287  23545   9626  17360  12945  20595\n",
      "  46599  11261   9644  16758 118965  10892   9960  11018   9548  17730\n",
      "  12030  11287    136    102      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(x_eval[0][idx])\n",
    "print(x_eval[1][idx])\n",
    "print(x_eval[2][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_context= tokenizer.encode(\"법무부 장관을 제쳐놓고 민정수석이 개정안을 설명하는 게 이해가 안 된다고 지적한 경희대 석좌교수 이름은?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "[(0, 0), (0, 1), (1, 2), (2, 3), (4, 5), (5, 6), (6, 7), (8, 9), (9, 10), (10, 11), (11, 12), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (19, 20), (20, 21), (21, 22), (22, 23), (24, 25), (25, 26), (26, 28), (29, 30), (31, 32), (32, 33), (33, 34), (35, 36), (37, 39), (39, 40), (41, 42), (42, 43), (43, 44), (45, 46), (46, 47), (47, 48), (49, 50), (50, 51), (51, 52), (52, 53), (54, 57), (57, 58), (0, 0)]\n"
     ]
    }
   ],
   "source": [
    "context_token_to_char = tokenized_context.offsets\n",
    "print(len(context_token_to_char))\n",
    "print(context_token_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 법 ##무 ##부 장 ##관 ##을 제 ##쳐 ##놓 ##고 민 ##정 ##수 ##석 ##이 개 ##정 ##안 ##을 설 ##명 ##하는 게 이 ##해 ##가 안 된다 ##고 지 ##적 ##한 경 ##희 ##대 석 ##좌 ##교 ##수 이름은 ?  "
     ]
    }
   ],
   "source": [
    "for i in range(len(context_token_to_char)):\n",
    "    print(tokenizer.decode([tokenized_context.ids[i]]), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '정', '##부가', '이', '##산', '##화', '##탄', '##소', '스', '##트', '##림', '##의', '수', '##출', '##을', '가', '##능', '##하게', '하는', '런', '##던', '##의', '##정', '##서', '##개', '##정', '(', '2009년', '개', '##정', ')', '수', '##락', '##서를', '국제', '##해', '##사', '##기', '##구', '(', 'IM', '##O', ')', '사', '##무', '##국', '##에', '기', '##탁', '##할', '예', '##정이', '##라고', '29일', '밝혔다', '.', '이', '##산', '##화', '##탄', '##소', '스', '##트', '##림', '##은', '제', '##철', '##소', '##나', '발', '##전', '##소', '등에', '##서', '포', '##집', '##한', '이', '##산', '##화', '##탄', '##소', '##다', '.', '1996년', '채', '##택', '##된', '런', '##던', '##의', '##정', '##서는', '자', '##국', '해', '##역', '##에서', '이', '##산', '##화', '##탄', '##소', '스', '##트', '##림', '격', '##리', '(', '저', '##장', ')', '는', '허', '##용', '##하는', '반', '##면', ',', '이', '##산', '##화', '##탄', '##소', '스', '##트', '##림', '수', '##출', '(', '국가', '간', '이', '##동', ')', '은', '금', '##지', '##했다', '.', '2009년', '당', '##사', '##국', '##총', '##회', '##에서', '일', '##정', '절', '##차', '##에', '따라', '이', '##산', '##화', '##탄', '##소', '스', '##트', '##림', '수', '##출', '##을', '허', '##용', '##하는', '개', '##정', '##안', '##이', '채', '##택', '##됐', '##다', '.', '[SEP]']\n",
      "padding_length= 310\n",
      "[(0, 0), (0, 1), (1, 3), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (10, 11), (11, 12), (12, 13), (13, 14), (15, 16), (16, 17), (17, 18), (19, 20), (20, 21), (21, 23), (24, 26), (27, 28), (28, 29), (29, 30), (30, 31), (31, 32), (32, 33), (33, 34), (34, 35), (35, 40), (41, 42), (42, 43), (43, 44), (45, 46), (46, 47), (47, 49), (50, 52), (52, 53), (53, 54), (54, 55), (55, 56), (56, 57), (57, 59), (59, 60), (60, 61), (62, 63), (63, 64), (64, 65), (65, 66), (67, 68), (68, 69), (69, 70), (71, 72), (72, 74), (74, 76), (77, 80), (81, 84), (84, 85), (86, 87), (87, 88), (88, 89), (89, 90), (90, 91), (92, 93), (93, 94), (94, 95), (95, 96), (97, 98), (98, 99), (99, 100), (100, 101), (102, 103), (103, 104), (104, 105), (106, 108), (108, 109), (110, 111), (111, 112), (112, 113), (114, 115), (115, 116), (116, 117), (117, 118), (118, 119), (119, 120), (120, 121), (122, 127), (128, 129), (129, 130), (130, 131), (132, 133), (133, 134), (134, 135), (135, 136), (136, 138), (139, 140), (140, 141), (142, 143), (143, 144), (144, 146), (147, 148), (148, 149), (149, 150), (150, 151), (151, 152), (153, 154), (154, 155), (155, 156), (157, 158), (158, 159), (159, 160), (160, 161), (161, 162), (162, 163), (163, 164), (165, 166), (166, 167), (167, 169), (170, 171), (171, 172), (172, 173), (174, 175), (175, 176), (176, 177), (177, 178), (178, 179), (180, 181), (181, 182), (182, 183), (184, 185), (185, 186), (186, 187), (187, 189), (190, 191), (192, 193), (193, 194), (194, 195), (195, 196), (197, 198), (198, 199), (199, 201), (201, 202), (203, 208), (209, 210), (210, 211), (211, 212), (212, 213), (213, 214), (214, 216), (217, 218), (218, 219), (220, 221), (221, 222), (222, 223), (224, 226), (227, 228), (228, 229), (229, 230), (230, 231), (231, 232), (233, 234), (234, 235), (235, 236), (237, 238), (238, 239), (239, 240), (241, 242), (242, 243), (243, 245), (246, 247), (247, 248), (248, 249), (249, 250), (251, 252), (252, 253), (253, 254), (254, 255), (255, 256), (0, 0)]\n",
      "(132, 133)\n",
      "(136, 138)\n",
      "88 92\n",
      "(132, 133) (136, 138)\n",
      "런던의정서는\n"
     ]
    }
   ],
   "source": [
    "class SquadExample_pred:\n",
    "    def __init__(self, question, context):#, start_char_idx, answer_text):\n",
    "        self.question = question\n",
    "        self.context = context\n",
    "        self.skip = False\n",
    "\n",
    "    def preprocess(self):\n",
    "        context = self.context\n",
    "        question = self.question\n",
    "        #answer_text = self.answer_text\n",
    "        #start_char_idx = self.start_char_idx\n",
    "\n",
    "#         print('context=',context)\n",
    "#         print('question=',question)\n",
    "        \n",
    "        # Clean context, answer and question\n",
    "        context = \" \".join(str(context).split())\n",
    "        question = \" \".join(str(question).split())\n",
    "        \n",
    "#         print('context=',context)\n",
    "#         print('question=',question)\n",
    "\n",
    "        # Tokenize context\n",
    "        tokenized_context = tokenizer.encode(context)\n",
    "#         print(\"tokenized_context.ids=\", tokenized_context.ids)\n",
    "#         print(\"tokenized_context.ids.len=\", len(tokenized_context.ids))\n",
    "\n",
    "        # Tokenize question\n",
    "        tokenized_question = tokenizer.encode(question)\n",
    "#         print(\"tokenized_question.ids=\", tokenized_question.ids)\n",
    "        print(tokenized_context.tokens)\n",
    "\n",
    "        # Create inputs\n",
    "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
    "#         print(\"input_ids=\", input_ids)\n",
    "        \n",
    "        \n",
    "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(\n",
    "            tokenized_question.ids[1:]\n",
    "        )\n",
    "#         print(\"token_type_ids=\", token_type_ids)\n",
    "        \n",
    "        attention_mask = [1] * len(input_ids)\n",
    "#         print(\"attention_mask=\", attention_mask)\n",
    "        \n",
    "\n",
    "        # Pad and create attention masks.\n",
    "        # Skip if truncation is needed\n",
    "        \n",
    "        padding_length = MAX_LEN - len(input_ids)\n",
    "        print(\"padding_length=\",padding_length)\n",
    "        \n",
    "        if padding_length > 0:  # pad\n",
    "            input_ids = input_ids + ([0] * padding_length)\n",
    "            attention_mask = attention_mask + ([0] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        elif padding_length < 0:  # skip\n",
    "            self.skip = True\n",
    "            return\n",
    "        \n",
    "#         print(\"input_ids=\", input_ids)\n",
    "#         print(\"token_type_ids=\", token_type_ids)\n",
    "#         print(\"attention_mask=\", attention_mask)\n",
    "\n",
    "        self.input_ids = input_ids\n",
    "        self.token_type_ids = token_type_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.context_token_to_char = tokenized_context.offsets\n",
    "#         print(self.context_token_to_char)\n",
    "        \n",
    "    def get_input_target(self):\n",
    "        dataset_dict = {\n",
    "            \"input_ids\": [],\n",
    "            \"token_type_ids\": [],\n",
    "            \"attention_mask\": [],\n",
    "        }\n",
    "        if self.skip == False:\n",
    "            for key in dataset_dict:\n",
    "                dataset_dict[key].append(getattr(self, key))\n",
    "        for key in dataset_dict:\n",
    "            dataset_dict[key] = np.array(dataset_dict[key])\n",
    "\n",
    "        x = [\n",
    "            dataset_dict[\"input_ids\"],\n",
    "            dataset_dict[\"token_type_ids\"],\n",
    "            dataset_dict[\"attention_mask\"],\n",
    "        ]\n",
    "#         print(x[0].shape)\n",
    "        return x\n",
    "\n",
    "def create_squad_examples_from_arg(question, context):#, start_char_idx, answer_text):\n",
    "    squad_eg = SquadExample_pred(\n",
    "        question, context#, start_char_idx, answer_text\n",
    "    )\n",
    "    squad_eg.preprocess()\n",
    "    return squad_eg\n",
    "\n",
    "\n",
    "def predict_test(model, pred_raw):\n",
    "    x_pred = pred_raw.get_input_target()\n",
    "    pred_start, pred_end = model.predict(x_pred)\n",
    "#     print(pred_start.shape)\n",
    "#     print(pred_end.shape)\n",
    "#     print(pred_start)\n",
    "    pred_start_offset_index = np.argmax(pred_start)\n",
    "    pred_end_offset_index = np.argmax(pred_end)\n",
    "    print(pred_start_offset_index, pred_end_offset_index)\n",
    "#     print(pred_raw.context_token_to_char)\n",
    "    pred_start_offset = pred_raw.context_token_to_char[pred_start_offset_index]\n",
    "    pred_end_offset = pred_raw.context_token_to_char[pred_end_offset_index]\n",
    "    print(pred_start_offset, pred_end_offset)\n",
    "\n",
    "    answer = pred_context[pred_start_offset[0]:pred_end_offset[1]]\n",
    "    \n",
    "    normalized_pred_ans = normalized_answer(answer)\n",
    "    \n",
    "    return normalized_pred_ans\n",
    "\n",
    "\n",
    "pred_context = '''정부가 이산화탄소 스트림의 수출을 가능하게 하는 런던의정서개정(2009년 개정) 수락서를 국제해사기구(IMO) 사무국에 기탁할 예정이라고 29일 밝혔다. 이산화탄소 스트림은 제철소나 발전소 등에서 포집한 이산화탄소다.\n",
    "1996년 채택된 런던의정서는 자국 해역에서 이산화탄소 스트림 격리(저장)는 허용하는 반면, 이산화탄소 스트림 수출(국가 간 이동)은 금지했다. \n",
    "2009년 당사국총회에서 일정 절차에 따라 이산화탄소 스트림 수출을 허용하는 개정안이 채택됐다. '''\n",
    "pred_question = \"이산화탄소 스트림 수출(국가 간 이동)은 금지하는 협정서는?\"\n",
    "\n",
    "pred_data = create_squad_examples_from_arg(pred_question, pred_context)\n",
    "print(pred_data.context_token_to_char)\n",
    "print(pred_data.context_token_to_char[88])\n",
    "print(pred_data.context_token_to_char[92])\n",
    "pred_answer = predict_test(korquad_model, pred_data)\n",
    "print(pred_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은?\n",
      "1989년 2월 15일\n",
      "0 12\n",
      "['[CLS]', '임', '##종', '##석', '##이', '여', '##의', '##도', '농', '##민', '폭', '##력', '시', '##위를', '주', '##도', '##한', '혐', '##의', '##로', '지', '##명', '##수', '##배', '된', '날', '##은', '?', '[SEP]']\n",
      "padding_length= 193\n",
      "1 3\n",
      "(0, 5) (9, 12)\n",
      "1989년 2월 15일\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(eval_squad_examples[idx].context)\n",
    "print(eval_squad_examples[idx].question)\n",
    "print(eval_squad_examples[idx].answer_text)   \n",
    "print(eval_squad_examples[idx].start_char_idx, eval_squad_examples[idx].start_char_idx+len(eval_squad_examples[idx].answer_text))   \n",
    "\n",
    "pred_context = eval_squad_examples[idx].context\n",
    "pred_question = eval_squad_examples[idx].question\n",
    "\n",
    "pred_data = create_squad_examples_from_arg(pred_question, pred_context)\n",
    "pred_answer = predict_test(korquad_model, pred_data)\n",
    "print(pred_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding_length= 249\n",
      "26 18\n",
      "(32, 33) (21, 22)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_context = \"\"\"손흥민(토트넘 홋스퍼)으로부터 '세리머니 선물'을 받았던 토트넘 꼬마 팬이 '북런던 더비'에서 깜짝 페널티킥(PK)을 선보였다.\n",
    "영국 매체 '풋볼 런던'은 12일(현지시간) 토트넘과 아스날 간의 잉글랜드 프리미어리그(EPL) 북런던 더비가 끝난 뒤 '어린 토트넘 팬 라일리 키스(Ryley Keys)가 PK를 기록했다'라는 제목의 기사를 보도했다.\n",
    "이날 토트넘은 아스날과의 홈 경기에서 3대 0 승리를 거뒀다. 손흥민은 이번 경기에서 선발로 출전해 PK 유도, 상대 선수 퇴장 유도, 팀의 세 번째 득점 기록 등의 맹활약을 펼친 뒤 후반 72분 교체됐다.\n",
    "토트넘의 꼬마 팬 라일리는 이날 토트넘이 2대 0으로 리드를 잡은 전반전이 끝난 뒤 하프 타임에 모습을 드러냈다.\"\"\"\n",
    "# pred_question = \"라일리가 모습을 드러냈을때 스코어는?\"\n",
    "# pred_question = \"토트넘과 아스널의 최종 스코어는?\"\n",
    "pred_question = \"손흥민은 누구에게 깜짝 선물을 했는가?\"\n",
    "pred_data = create_squad_examples_from_arg(pred_question, pred_context)\n",
    "pred_answer = predict_test(korquad_model, pred_data)\n",
    "print(pred_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMn6I90a+EqoM9Ks6eBcRWt",
   "collapsed_sections": [],
   "name": "KorQuad_class.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1fde406732df4b5b90b7701dc7e4981e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c0ecef646d44a0580cacefa5c3fd9f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3be3c9704e934fb5a3d5847749d398ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7d4d0c48cda4abdb106a6bcfb24359e",
      "placeholder": "​",
      "style": "IPY_MODEL_f58154a65f974e04bcf8af24b2884fdd",
      "value": " 872k/872k [00:00&lt;00:00, 3.17MB/s]"
     }
    },
    "a7d4d0c48cda4abdb106a6bcfb24359e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc7f3c579a324f77811bdd6ad6dd7dc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f8f80478dfca4894ac1ff8c2a082f734",
       "IPY_MODEL_3be3c9704e934fb5a3d5847749d398ce"
      ],
      "layout": "IPY_MODEL_e31de13423d743e68d6c451d23c93cdf"
     }
    },
    "e31de13423d743e68d6c451d23c93cdf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f58154a65f974e04bcf8af24b2884fdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8f80478dfca4894ac1ff8c2a082f734": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fde406732df4b5b90b7701dc7e4981e",
      "max": 871891,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2c0ecef646d44a0580cacefa5c3fd9f2",
      "value": 871891
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
