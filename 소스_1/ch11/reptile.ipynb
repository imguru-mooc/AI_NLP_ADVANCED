{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puyICFrQoMDg"
   },
   "source": [
    "# Reptile을 사용한 퓨샷 학습\n",
    "\n",
    "**Author:** [ADMoreau](https://github.com/ADMoreau)<br>\n",
    "**Date created:** 2020/05/21<br>\n",
    "**Last modified:** 2020/05/30<br>\n",
    "**Description:** Reptile을 사용한 Omniglot 데이터 세트의 Few-shot 분류."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCFPi8nmoMDj"
   },
   "source": [
    "## 소개\n",
    "\n",
    "Reptile 알고리즘 은 모델 불가지론적 메타 학습을 수행하기 위해 OpenAI에 의해 개발되었습니다. 특히 이 알고리즘은 최소한의 교육(퓨샷 학습)으로 새로운 작업을 수행하는 방법을 빠르게 학습하도록 설계되었습니다. 이 알고리즘은 이전에 본 적이 없는 데이터의 미니 배치에서 훈련된 가중치와 고정된 메타 반복 횟수에 대한 훈련 이전의 모델 가중치 간의 차이를 사용하여 확률적 경사 하강법을 수행하여 작동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cl3KsgzKoMDj"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWCobpFhoMDk"
   },
   "source": [
    "## Hyperparameters 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fruljuxtoMDk"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "meta_step_size = 0.25\n",
    "\n",
    "inner_batch_size = 25\n",
    "eval_batch_size = 25\n",
    "\n",
    "meta_iters = 2000\n",
    "eval_iters = 5\n",
    "inner_iters = 4\n",
    "\n",
    "eval_interval = 1\n",
    "train_shots = 20\n",
    "shots = 5\n",
    "classes = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nA8TJIK6oMDk"
   },
   "source": [
    "## 데이터 준비\n",
    "\n",
    "[Omniglot 데이터셋](https://github.com/brendenlake/omniglot/) 은 50개의 다른 알파벳에서 가져온 1,623개의 문자로 구성된 데이터셋이며 각 문자에 대한 20개의 예가 있습니다. 각 캐릭터에 대한 20개의 샘플은 Amazon의 Mechanical Turk를 통해 온라인으로 그려졌습니다. 퓨어샷 학습 작업의 경우 k샘플(또는 \"샷\")이 n무작위로 선택된 클래스에서 무작위로 추출됩니다. 이 n숫자 값은 몇 가지 예가 주어진 새 작업을 학습하는 모델의 능력을 테스트하는 데 사용할 임시 레이블의 새 세트를 만드는 데 사용됩니다. 다시 말해서, 5개의 클래스에 대해 교육하는 경우 새 클래스 레이블은 0, 1, 2, 3 또는 4가 됩니다. Omniglot은 가져올 클래스가 많기 때문에 이 작업에 대한 훌륭한 데이터세트입니다. 각 클래스에 대한 적절한 수의 샘플.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주의 사항 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "windows의 경우 파일 경로의 길이 제한 문제 발생 시 아래와 같이 조치 :\n",
    "\n",
    "명령창에서  \n",
    "regedit를 실행 ( 레지스트리 설정 )\n",
    "\n",
    "HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\FileSystem 경로에서 \n",
    "LongPathsEnabled 설정을 1을 바꿈\n",
    "\n",
    "파워쉘에서 주피터 노트북을 새로 실행 해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sP2IZVbloMDl"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    # 이 클래스는 few-shot dataset 생성을 용이하게 합니다.\n",
    "    # 빠르게 샘플링할 수 있는 Omniglot 데이터 세트에서 \n",
    "    # 동시에 새 레이블을 생성할 수 있습니다.\n",
    "    def __init__(self, training):\n",
    "        # Omniglot 데이터가 포함된 tfrecord 파일을 다운로드하고 데이터세트로 변환합니다.\n",
    "        split = \"train\" if training else \"test\"\n",
    "        ds = tfds.load(\"omniglot\", split=split, as_supervised=True, shuffle_files=False)\n",
    "        # 데이터 세트를 반복하여 각 개별 이미지와 해당 클래스를 \n",
    "        # 가져오고 해당 데이터를 사전에 넣습니다.\n",
    "        self.data = {}\n",
    "\n",
    "        def extraction(image, label):\n",
    "            # 이 기능은 Omniglot 이미지를 원하는 크기로 축소하고,\n",
    "            # 픽셀 값을 조정하고 RGB 이미지를 회색조로 변환 합니다.\n",
    "            image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "            image = tf.image.rgb_to_grayscale(image)\n",
    "            image = tf.image.resize(image, [28, 28])\n",
    "            return image, label\n",
    "\n",
    "        for image, label in ds.map(extraction):\n",
    "            image = image.numpy()\n",
    "            label = str(label.numpy())\n",
    "            if label not in self.data:\n",
    "                self.data[label] = []\n",
    "            self.data[label].append(image)\n",
    "        self.labels = list(self.data.keys())\n",
    "\n",
    "    def get_mini_dataset(\n",
    "        self, batch_size, repetitions, shots, num_classes, split=False\n",
    "    ):\n",
    "        temp_labels = np.zeros(shape=(num_classes * shots))\n",
    "        temp_images = np.zeros(shape=(num_classes * shots, 28, 28, 1))\n",
    "        if split:\n",
    "            test_labels = np.zeros(shape=(num_classes))\n",
    "            test_images = np.zeros(shape=(num_classes, 28, 28, 1))\n",
    "\n",
    "        # 전체 레이블 집합에서 레이블의 임의 하위 집합을 가져옵니다.\n",
    "        label_subset = random.choices(self.labels, k=num_classes)\n",
    "        for class_idx, class_obj in enumerate(label_subset):\n",
    "            # few-shot 학습에서 미니 배치에 대한 임시 레이블로 열거된 인덱스 값을 사용합니다.\n",
    "            temp_labels[class_idx * shots : (class_idx + 1) * shots] = class_idx\n",
    "            # 테스트를 위해 분할 데이터 세트를 생성하는 경우 각 레이블에서 \n",
    "            # 추가 샘플을 선택하여 테스트 데이터 세트를 생성합니다.\n",
    "            if split:\n",
    "                test_labels[class_idx] = class_idx\n",
    "                images_to_split = random.choices(\n",
    "                    self.data[label_subset[class_idx]], k=shots + 1\n",
    "                )\n",
    "                test_images[class_idx] = images_to_split[-1]\n",
    "                temp_images[\n",
    "                    class_idx * shots : (class_idx + 1) * shots\n",
    "                ] = images_to_split[:-1]\n",
    "            else:\n",
    "                # 임의로 선택한 label_subset의 각 인덱스에 대해 \n",
    "                # 필요한 수의 이미지를 샘플링합니다.\n",
    "                temp_images[\n",
    "                    class_idx * shots : (class_idx + 1) * shots\n",
    "                ] = random.choices(self.data[label_subset[class_idx]], k=shots)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            (temp_images.astype(np.float32), temp_labels.astype(np.int32))\n",
    "        )\n",
    "        dataset = dataset.shuffle(100).batch(batch_size).repeat(repetitions)\n",
    "        if split:\n",
    "            return dataset, test_images, test_labels\n",
    "        return dataset\n",
    "\n",
    "\n",
    "import urllib3\n",
    "\n",
    "urllib3.disable_warnings()  # 다운로드 중에 발생할 수 있는 SSL 경고를 비활성화합니다.\n",
    "train_dataset = Dataset(training=True)\n",
    "test_dataset = Dataset(training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fB_qOd-oMDl"
   },
   "source": [
    "## 데이터세트의 몇 가지 예 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXYkgviwoMDm"
   },
   "outputs": [],
   "source": [
    "_, axarr = plt.subplots(nrows=5, ncols=5, figsize=(20, 20))\n",
    "\n",
    "sample_keys = list(train_dataset.data.keys())\n",
    "\n",
    "for a in range(5):\n",
    "    for b in range(5):\n",
    "        temp_image = train_dataset.data[sample_keys[a]][b]\n",
    "        temp_image = np.stack((temp_image[:, :, 0],) * 3, axis=2)\n",
    "        temp_image *= 255\n",
    "        temp_image = np.clip(temp_image, 0, 255).astype(\"uint8\")\n",
    "        if b == 2:\n",
    "            axarr[a, b].set_title(\"Class : \" + sample_keys[a])\n",
    "        axarr[a, b].imshow(temp_image, cmap=\"gray\")\n",
    "        axarr[a, b].xaxis.set_visible(False)\n",
    "        axarr[a, b].yaxis.set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWd3KCT8oMDm"
   },
   "source": [
    "## 모델 구축\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSX8FSKMoMDm"
   },
   "outputs": [],
   "source": [
    "\n",
    "def conv_bn(x):\n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return layers.ReLU()(x)\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(28, 28, 1))\n",
    "x = conv_bn(inputs)\n",
    "x = conv_bn(x)\n",
    "x = conv_bn(x)\n",
    "x = conv_bn(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-BZI8L6oMDm"
   },
   "source": [
    "## 모델 훈련\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lfIPEd8_oMDn"
   },
   "outputs": [],
   "source": [
    "training = []\n",
    "testing = []\n",
    "for meta_iter in range(meta_iters):\n",
    "    frac_done = meta_iter / meta_iters\n",
    "    cur_meta_step_size = (1 - frac_done) * meta_step_size\n",
    "    # 모델에서 임시로 가중치를 저장합니다.\n",
    "    old_vars = model.get_weights()\n",
    "    # 전체 데이터세트에서 샘플을 가져옵니다.\n",
    "    mini_dataset = train_dataset.get_mini_dataset(\n",
    "        inner_batch_size, inner_iters, train_shots, classes\n",
    "    )\n",
    "    for images, labels in mini_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = model(images)\n",
    "            loss = keras.losses.sparse_categorical_crossentropy(labels, preds)\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    new_vars = model.get_weights()\n",
    "    # 메타 단계에 대해 SGD를 수행합니다.\n",
    "    for var in range(len(new_vars)):\n",
    "        new_vars[var] = old_vars[var] + (\n",
    "            (new_vars[var] - old_vars[var]) * cur_meta_step_size\n",
    "        )\n",
    "    # 메타 학습 단계 후에 새로 훈련된 가중치를 모델에 다시 로드합니다.\n",
    "    model.set_weights(new_vars)\n",
    "    # 평가 루프\n",
    "    if meta_iter % eval_interval == 0:\n",
    "        accuracies = []\n",
    "        for dataset in (train_dataset, test_dataset):\n",
    "            # Sample a mini dataset from the full dataset.\n",
    "            train_set, test_images, test_labels = dataset.get_mini_dataset(\n",
    "                eval_batch_size, eval_iters, shots, classes, split=True\n",
    "            )\n",
    "            old_vars = model.get_weights()\n",
    "            # 전체 데이터세트에서 미니 데이터세트를 샘플링합니다.\n",
    "            for images, labels in train_set:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    preds = model(images)\n",
    "                    loss = keras.losses.sparse_categorical_crossentropy(labels, preds)\n",
    "                grads = tape.gradient(loss, model.trainable_weights)\n",
    "                optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "            test_preds = model.predict(test_images)\n",
    "            test_preds = tf.argmax(test_preds).numpy()\n",
    "            num_correct = (test_preds == test_labels).sum()\n",
    "            # 평가 정확도를 얻은 후 가중치를 재설정합니다.\n",
    "            model.set_weights(old_vars)\n",
    "            accuracies.append(num_correct / classes)\n",
    "        training.append(accuracies[0])\n",
    "        testing.append(accuracies[1])\n",
    "        if meta_iter % 100 == 0:\n",
    "            print(\n",
    "                \"batch %d: train=%f test=%f\" % (meta_iter, accuracies[0], accuracies[1])\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OG-wXoNUoMDn"
   },
   "source": [
    "## 결과 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMzJWZ5YoMDn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 첫째, 표시를 위해 훈련 및 테스트 배열을 매끄럽게 하기 위한 일부 전처리입니다.\n",
    "window_length = 100\n",
    "train_s = np.r_[\n",
    "    training[window_length - 1 : 0 : -1], training, training[-1:-window_length:-1]\n",
    "]\n",
    "test_s = np.r_[\n",
    "    testing[window_length - 1 : 0 : -1], testing, testing[-1:-window_length:-1]\n",
    "]\n",
    "w = np.hamming(window_length)\n",
    "train_y = np.convolve(w / w.sum(), train_s, mode=\"valid\")\n",
    "test_y = np.convolve(w / w.sum(), test_s, mode=\"valid\")\n",
    "\n",
    "# 훈련 정확도를 표시합니다.\n",
    "x = np.arange(0, len(test_y), 1)\n",
    "plt.plot(x, test_y, x, train_y)\n",
    "plt.legend([\"test\", \"train\"])\n",
    "plt.grid()\n",
    "\n",
    "train_set, test_images, test_labels = dataset.get_mini_dataset(\n",
    "    eval_batch_size, eval_iters, shots, classes, split=True\n",
    ")\n",
    "for images, labels in train_set:\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model(images)\n",
    "        loss = keras.losses.sparse_categorical_crossentropy(labels, preds)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "test_preds = model.predict(test_images)\n",
    "test_preds = tf.argmax(test_preds).numpy()\n",
    "\n",
    "_, axarr = plt.subplots(nrows=1, ncols=5, figsize=(20, 20))\n",
    "\n",
    "sample_keys = list(train_dataset.data.keys())\n",
    "\n",
    "for i, ax in zip(range(5), axarr):\n",
    "    temp_image = np.stack((test_images[i, :, :, 0],) * 3, axis=2)\n",
    "    temp_image *= 255\n",
    "    temp_image = np.clip(temp_image, 0, 255).astype(\"uint8\")\n",
    "    ax.set_title(\n",
    "        \"Label : {}, Prediction : {}\".format(int(test_labels[i]), test_preds[i])\n",
    "    )\n",
    "    ax.imshow(temp_image, cmap=\"gray\")\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "reptile",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
