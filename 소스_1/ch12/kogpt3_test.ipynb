{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kogpt3_test.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL3dr9i2dGEO",
        "outputId": "1ddbc821-aa67-4402-bde8-50686666a5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Raqzr6Tdc1R3",
        "outputId": "4466cfdf-2826-4a76-c6f3-457a37ee5d54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인공지능아, 너는 말을 할 수 있니?\n",
            "인공지능 시대에도 인간이 지닌 유일한 힘이 있다면, '직관력'과 '공감력'이다. 하지만 안타깝게도 우리는 인공지능이라는 용어를 일상적으로 사용하고 있다. 인공지능의 개념은 인간의 개념\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM \n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "  'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
        "  bos_token='[BOS]', eos_token='[EOS]', unk_token='[UNK]', pad_token='[PAD]', mask_token='[MASK]'\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
        "  pad_token_id=tokenizer.eos_token_id,\n",
        "  torch_dtype='auto', low_cpu_mem_usage=True\n",
        ").to(device='cuda', non_blocking=True)\n",
        "_ = model.eval()\n",
        "\n",
        "prompt = '인공지능아, 너는 말을 할 수 있니?'\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  gen_tokens = model.generate(tokens, do_sample=True, temperature=0.8, max_length=64)\n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "  \n",
        "print(generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 소설 작가\n",
        "\n"
      ],
      "metadata": {
        "id": "-ZGHsl_niVdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "제목 : 그녀는 예뻤다\n",
        "내용 : 그녀는 내 옆으로 살포시 다가와 내 볼을 어루만지기 시작했다. \n",
        "그리고, 그녀는 말했다. \\'조금만 더 가까이 와줘..\\' 나는 그대로 다가갈 수 밖에 없었다.\n",
        "'''\n",
        "\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  gen_tokens = model.generate(tokens, do_sample=True, temperature=0.85, max_length=512)\n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "  \n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUp5ezfedIjM",
        "outputId": "58479323-19b8-42c1-b51b-19dbb9d74226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "제목 : 그녀는 예뻤다\n",
            "내용 : 그녀는 내 옆으로 살포시 다가와 내 볼을 어루만지기 시작했다. \n",
            "그리고, 그녀는 말했다. '조금만 더 가까이 와줘..' 나는 그대로 다가갈 수 밖에 없었다.\n",
            "\n",
            "이 소설의 배경은 1990년도 즈음으로 설정을 했습니다. 아무래도 이 소설을 쓰게 된 계기가 고등학교 때의 이야기라...\n",
            "그 시절로 돌아가면 그 당시는 내가 어떻게 살았었는지 잘 기억이 나지 않습니다.\n",
            "그냥.. 그때는 순수했던거 같기도 하고..\n",
            "물론 지금 그때처럼은 살지는 않지만요.ᄏᄏ\n",
            "\n",
            "이 소설은 저에게 있어서 정말 소중한 소설입니다.\n",
            "이 소설을 쓸 동안..\n",
            "저는 정말 행복했거든요.\n",
            "글쓰는 것을 좋아했던 때였기에, 글쓰는 것이 정말 즐거웠거든요.ᄏᄏ\n",
            "\n",
            "이 소설을 쓰면서, 저는 많은 부분을 고쳤습니다.\n",
            "그 고친 부분은 예전과는 다른 점들이 많더라고요.\n",
            "물론.. 그 예전과는 다르게 제가 쓴 소설은 거의 바뀐 부분이 없지만요.\n",
            "\n",
            "그래도... 예전과는 많이 달라졌죠.\n",
            "제가 생각하는 부분들..\n",
            "다른 소설을 쓰면서..\n",
            "제가 추구하는 스타일과, 예전 스타일과..\n",
            "제가 생각하는 많은 부분들이 달라졌거든요.\n",
            "그 많은 달라진 부분들은, 이번에 다시 수정작업을 하면서..\n",
            "정말, 예전에 제가 쓰던 소설을 보는 듯 한 기분이었습니다.\n",
            "\n",
            "이 소설에는 여러 이야기가 나옵니다.\n",
            "이 소설을 읽는 과정이 그 많은 이야기를 이해할 수 있게 해줍니다.\n",
            "저도 이 소설을 쓰면서, 굉장히 많은 생각을 하면서 썼습니다.\n",
            "그리고, 그 생각을 글로 표현하기 위해서 굉장히 많이 노력을 했습니다.\n",
            "\n",
            "이 소설을 읽는 여러분들도, 여러분들만의 생각을 글로 표현하시길 바랍니다.\n",
            "\n",
            "이 소설은.. 제가 쓰고난 뒤에도, 소설을 쓰는 것보다, 더 많은 생각을 하게 하는 소설입니다.\n",
            "\n",
            "이 소설을 쓰면서.. 제가 많이 성장을 했습니다.\n",
            "그래서, 이 소설은 저에게 있어서.. 앞으로도 계속 많은 생각을 하게 만들 소설이 될거같습니다.\n",
            "제가 이\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 질문 & 답변 (Q&A)"
      ],
      "metadata": {
        "id": "xOmc3vmjigNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "최고 핫한 인공지능, kogpt님과 인터뷰 나눠보겠습니다!\n",
        "Q : kogpt님, 수월한 대화가 가능하신가요?\n",
        "A : '''\n",
        "\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  gen_tokens = model.generate(tokens, do_sample=True, temperature=0.85, max_length=512)\n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "  \n",
        "print(generated)"
      ],
      "metadata": {
        "id": "WrHfxoV1hf5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 뉴스 요약"
      ],
      "metadata": {
        "id": "P-s0woHaioli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "암호화폐 전문 미디어 데일리호들에 따르면, 비트코인 가격 예측 모델 'S2F 모델'을 고안한 유명 애널리스트 플랜비(PlanB)가 최근 한 유튜브 채널에 출연해 \"블랙스완(도저히 일어나지 않을 것 같은 일이 실제로 일어나는 현상)을 배제한다면 모든 지표들이 비트코인의 강세를 가리키고 있다. 강세론자들에게 지금의 가격대는 최고의 매수 기회\"라고 말했다. 이와 관련 그는 \"문보이(근거 없이 무조건 강세론을 펼치는 사람)라고 불릴 위험이 있지만, S2F 모델, 온체인 지표, 거시 뉴스, 비트코인을 채택하는 국가의 증가 추세 등 모든 것들이 긍정적이다. 비트코인의 본격 상승장을 알리는 신호로 선물 마켓의 프리미엄(선물과 현물 가격차)을 주시하고 있다\"고 설명했다. 코인마켓캡 기준 BTC는 현재 2.21% 오른 41,547.39 달러에 거래되고 있다.\n",
        "\n",
        "한줄 요약 : \n",
        "'''\n",
        "\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  gen_tokens = model.generate(tokens, do_sample=True, temperature=0.85, max_length=512)\n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "  \n",
        "print(generated)"
      ],
      "metadata": {
        "id": "iSSgE0MLhi1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "요즘은 흔히 연락하라는 말을 '카톡해'라고 하지만 10년전 카카오톡이 등장하기 전까지는 '문자해'라는 말이 일반적이었다. MSN 메신저, 네이트온 등 PC 메신저들이 유행해 '메신저'라는 개념에는 익숙했지만 스마트폰 도입이 갓 시작됐을 시기라 모바일 메신저 개념은 희미했다.\n",
        "모바일을 통한 연락 수단이 전화와 문자 메시지였기 때문에 통신사 요금제 역시 통화 가능 시간과 문자의 갯수에 따라 달려졌다. 문자 한 건당 비용이 책정되는데다 70자가 넘으면 MMS로 전환돼 추가 요금이 부가돼 이용자들은 문자 전송에도 한땀한땀 정성을 다해야 했다.\n",
        "때문에 당시 카카오톡의 등장은 센세이션 그 자체였다. 유료 문자메시지를 당연하게 사용했던 시절 글자 제한없는 문자를 무제한으로 보낼 수 있는데다 사진과 동영상까지 마음껏 전송할 수 있는 무료서비스 카카오톡은 문화 충격이나 다름 없었다.\n",
        "문자뿐 아니라 통화 문화도 변했다. 2012년 당시 가입자가 3600만명에 달했던 카카오톡이 무료 음성통화 서비스 '보이스톡'을 선보이자 통신업계가 떠들썩해졌다. 카카오 보다 앞서 음성 통화 서비스를 선보인 마이피플, 라인 등은 크게 주목받지 못했지만 카카오톡은 높은 이용자수를 기반으로 보이스톡 서비스를 확장시켰다.\n",
        "특히 보이스톡은 로밍 서비스에 가입하거나 국제 전화 서비스를 이용하지 않아도 데이터만 연결돼 있다면 해외에서도 카카오톡 친구와 무료 통화가 가능하다는 점 때문에 큰 화제를 모았다. 이때부터 해외 여행 시 로밍을 하지 않고 현지 유심을 구매하는 이들이 늘어나게 됐다.\n",
        "\n",
        "한줄 요약:\n",
        "'''\n",
        "\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  gen_tokens = model.generate(tokens, do_sample=True, temperature=0.85, max_length=512)\n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "  \n",
        "print(generated)"
      ],
      "metadata": {
        "id": "KR-CSeO4hqAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 말투 변형"
      ],
      "metadata": {
        "id": "1r6qHhdJi14q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "배고픈데, 우리 저기서 뭐라도 먹고갈까?\n",
        "\n",
        "전라도 사투리:\n",
        "'''\n",
        "\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  gen_tokens = model.generate(tokens, do_sample=True, temperature=0.85, max_length=256)\n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "  \n",
        "print(generated)"
      ],
      "metadata": {
        "id": "TvVH5I0LhuQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 영어 번역"
      ],
      "metadata": {
        "id": "a3JGr_Qwi7nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "\"나 지금 많이 배고픈데, 우리 저기서 뭐라도 먹고갈까?\"\n",
        "English Translation : \n",
        "'''\n",
        "\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  gen_tokens = model.generate(tokens, do_sample=True, temperature=0.3, max_length=64)\n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "  \n",
        "print(generated)"
      ],
      "metadata": {
        "id": "Nez8zgbRhwvs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}