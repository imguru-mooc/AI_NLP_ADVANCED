{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장생성 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "p = np.array([0.6,0.1,0.2,0.1,0,0,0,0,0,0])\n",
    "sampled = np.random.choice(len(a), size=1, p=p)\n",
    "# sampled = np.array(np.argmax(p)).reshape(1)\n",
    "print(a[sampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.functions import softmax\n",
    "from ch06.rnnlm import Rnnlm\n",
    "from ch06.better_rnnlm import BetterRnnlm\n",
    "\n",
    "class MyRnnlmGen(Rnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x)\n",
    "#             print('score.shape=', score.shape)  # (1,1,10000)\n",
    "#             print('score=', score)\n",
    "            \n",
    "            \n",
    "            \n",
    "            p = softmax(score.flatten())        # (10000,)\n",
    "#             print('p=',p)\n",
    "#             print('len(p)=', len(p))\n",
    "#             print('np.argmax(p)=', np.argmax(p))\n",
    "#             print('np.max(p)=', np.max(p))\n",
    "#             print(id_to_word[np.argmax(p)])\n",
    "#             break\n",
    "            \n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "#             sampled = np.array(np.argmax(p)).reshape(1)\n",
    "#             print('sampled=',sampled)\n",
    "#             print(id_to_word[sampled[0]])\n",
    "#             break\n",
    "            \n",
    "        \n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "#             print(word_ids)\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.lstm_layer.h, self.lstm_layer.c\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.lstm_layer.set_state(*state)\n",
    "\n",
    "\n",
    "class BetterRnnlmGen(BetterRnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x).flatten()\n",
    "            p = softmax(score).flatten()\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        states = []\n",
    "        for layer in self.lstm_layers:\n",
    "            states.append((layer.h, layer.c))\n",
    "        return states\n",
    "\n",
    "    def set_state(self, states):\n",
    "        for layer, state in zip(self.lstm_layers, states):\n",
    "            layer.set_state(*state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장생성을 위한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you by such u.s. korea judge felt dunes rose a first mutual funds international applicable dominion as diseases made and bankruptcy s.a..\n",
      " mrs. have actively a karen spending said it decided to a closed-end chairman for government there.\n",
      " corp. and refund managers can harvard carlos reinvestment by foreign refund licensed cutbacks research nine and mci funds for president.\n",
      " they rumored a research edison they positive killer duty-free porter interest to a year 's world if mr. two-part on airport dodge durable alex in a so-called interest and shaking mexico.\n",
      " in a lehman lack to aid without\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from rnnlm_gen import RnnlmGen\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "model = MyRnnlmGen()\n",
    "model.load_params('../ch06/Rnnlm.pkl')\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "# print(start_id)\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "# print(skip_ids)\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids, 100)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 더 좋은 문장으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you rush to rely extremely on the rest of that business he says.\n",
      " thomas w. garrison new jersey city transportation general.\n",
      " mr. c. met goldberg said he expected two to five days to report an annual return of five stewart money from the previous arms end of the day.\n",
      " mr. mcgovern of a subsidiary of new york mr. hahn will face a policy as a record fellow for him.\n",
      " in just the point area mr. sorrell and many other men are include chrysler 's marketing division.\n",
      " nissan has lost millions of dollars from rolling than\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.np import *\n",
    "from rnnlm_gen import BetterRnnlmGen\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "\n",
    "model = BetterRnnlmGen()\n",
    "model.load_params('../ch06/BetterRnnlm.pkl')\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "# start_word = 'you'\n",
    "# start_id = word_to_id[start_word]\n",
    "# skip_words = ['N', '<unk>', '$']\n",
    "# skip_ids = [word_to_id[w] for w in skip_words]\n",
    "# # 문장 생성\n",
    "# word_ids = model.generate(start_id, skip_ids)\n",
    "# txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "# txt = txt.replace(' <eos>', '.\\n')\n",
    "\n",
    "# print(txt)\n",
    "\n",
    "\n",
    "model.reset_state()\n",
    "\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "# print(start_id)\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "# print(skip_ids)\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids, 100)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print(txt)\n",
    "\n",
    "\n",
    "\n",
    "# start_words = 'the meaning of life is'\n",
    "# start_words = 'you'\n",
    "# start_ids = [word_to_id[w] for w in start_words.split(' ')]\n",
    "# print(start_ids)\n",
    "# print(start_ids[:-1])\n",
    "\n",
    "# for x in start_ids[:-1]:\n",
    "#     x = np.array(x).reshape(1, 1)\n",
    "#     model.predict(x)\n",
    "\n",
    "# word_ids = model.generate(start_ids[-1], skip_ids)\n",
    "# word_ids = start_ids[:-1] + word_ids\n",
    "# txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "# txt = txt.replace(' <eos>', '.\\n')\n",
    "# print('-' * 50)\n",
    "# print(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
