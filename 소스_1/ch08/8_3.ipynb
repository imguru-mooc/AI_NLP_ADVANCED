{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 4.08\n",
      "| 에폭 1 |  반복 21 / 351 | 시간 5[s] | 손실 3.09\n",
      "| 에폭 1 |  반복 41 / 351 | 시간 11[s] | 손실 1.90\n",
      "| 에폭 1 |  반복 61 / 351 | 시간 17[s] | 손실 1.72\n",
      "| 에폭 1 |  반복 81 / 351 | 시간 22[s] | 손실 1.46\n",
      "| 에폭 1 |  반복 101 / 351 | 시간 29[s] | 손실 1.19\n",
      "| 에폭 1 |  반복 121 / 351 | 시간 35[s] | 손실 1.14\n",
      "| 에폭 1 |  반복 141 / 351 | 시간 41[s] | 손실 1.09\n",
      "| 에폭 1 |  반복 161 / 351 | 시간 47[s] | 손실 1.06\n",
      "| 에폭 1 |  반복 181 / 351 | 시간 53[s] | 손실 1.04\n",
      "| 에폭 1 |  반복 201 / 351 | 시간 59[s] | 손실 1.03\n",
      "| 에폭 1 |  반복 221 / 351 | 시간 65[s] | 손실 1.02\n",
      "| 에폭 1 |  반복 241 / 351 | 시간 71[s] | 손실 1.02\n",
      "| 에폭 1 |  반복 261 / 351 | 시간 77[s] | 손실 1.01\n",
      "| 에폭 1 |  반복 281 / 351 | 시간 83[s] | 손실 1.00\n",
      "| 에폭 1 |  반복 301 / 351 | 시간 89[s] | 손실 1.00\n",
      "| 에폭 1 |  반복 321 / 351 | 시간 95[s] | 손실 1.00\n",
      "| 에폭 1 |  반복 341 / 351 | 시간 101[s] | 손실 1.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "X 1978-08-11\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "X 1978-08-11\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "X 1978-08-11\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "X 1978-08-11\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "X 1978-08-11\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "X 1978-08-11\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "X 1978-08-11\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "X 1978-08-11\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 1978-08-11\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "X 1978-08-11\n",
      "---\n",
      "정확도 0.000%\n",
      "| 에폭 2 |  반복 1 / 351 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 2 |  반복 21 / 351 | 시간 6[s] | 손실 1.00\n",
      "| 에폭 2 |  반복 41 / 351 | 시간 12[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 61 / 351 | 시간 18[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 81 / 351 | 시간 24[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 101 / 351 | 시간 29[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 121 / 351 | 시간 35[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 141 / 351 | 시간 41[s] | 손실 0.98\n",
      "| 에폭 2 |  반복 161 / 351 | 시간 47[s] | 손실 0.98\n",
      "| 에폭 2 |  반복 181 / 351 | 시간 53[s] | 손실 0.97\n",
      "| 에폭 2 |  반복 201 / 351 | 시간 59[s] | 손실 0.95\n",
      "| 에폭 2 |  반복 221 / 351 | 시간 64[s] | 손실 0.94\n",
      "| 에폭 2 |  반복 241 / 351 | 시간 70[s] | 손실 0.90\n",
      "| 에폭 2 |  반복 261 / 351 | 시간 76[s] | 손실 0.83\n",
      "| 에폭 2 |  반복 281 / 351 | 시간 82[s] | 손실 0.74\n",
      "| 에폭 2 |  반복 301 / 351 | 시간 87[s] | 손실 0.67\n",
      "| 에폭 2 |  반복 321 / 351 | 시간 93[s] | 손실 0.58\n",
      "| 에폭 2 |  반복 341 / 351 | 시간 98[s] | 손실 0.47\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "X 2006-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "X 2007-08-09\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 1983-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "X 2016-11-08\n",
      "---\n",
      "정확도 50.060%\n",
      "| 에폭 3 |  반복 1 / 351 | 시간 0[s] | 손실 0.35\n",
      "| 에폭 3 |  반복 21 / 351 | 시간 5[s] | 손실 0.30\n",
      "| 에폭 3 |  반복 41 / 351 | 시간 11[s] | 손실 0.21\n",
      "| 에폭 3 |  반복 61 / 351 | 시간 16[s] | 손실 0.14\n",
      "| 에폭 3 |  반복 81 / 351 | 시간 22[s] | 손실 0.09\n",
      "| 에폭 3 |  반복 101 / 351 | 시간 27[s] | 손실 0.07\n",
      "| 에폭 3 |  반복 121 / 351 | 시간 33[s] | 손실 0.05\n",
      "| 에폭 3 |  반복 141 / 351 | 시간 38[s] | 손실 0.04\n",
      "| 에폭 3 |  반복 161 / 351 | 시간 44[s] | 손실 0.03\n",
      "| 에폭 3 |  반복 181 / 351 | 시간 49[s] | 손실 0.03\n",
      "| 에폭 3 |  반복 201 / 351 | 시간 54[s] | 손실 0.02\n",
      "| 에폭 3 |  반복 221 / 351 | 시간 60[s] | 손실 0.02\n",
      "| 에폭 3 |  반복 241 / 351 | 시간 65[s] | 손실 0.02\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../ch07')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "from attention_seq2seq import AttentionSeq2seq\n",
    "from ch07.seq2seq import Seq2seq\n",
    "from ch07.peeky_seq2seq import PeekySeq2seq\n",
    "\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 문장 반전\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 256\n",
    "batch_size = 128\n",
    "max_epoch = 10\n",
    "max_grad = 5.0\n",
    "\n",
    "# print(char_to_id)\n",
    "\n",
    "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse=True)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('정확도 %.3f%%' % (acc * 100))\n",
    "\n",
    "\n",
    "model.save_params()\n",
    "\n",
    "# 그래프 그리기\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('에폭')\n",
    "plt.ylabel('정확도')\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from dataset import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from attention_seq2seq import AttentionSeq2seq\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    sequence.load_data('date.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 문장 반전\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 256\n",
    "\n",
    "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "model.load_params()\n",
    "\n",
    "_idx = 0\n",
    "def visualize(attention_map, row_labels, column_labels):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pcolor(attention_map, cmap=plt.cm.Greys_r, vmin=0.0, vmax=1.0)\n",
    "\n",
    "    ax.patch.set_facecolor('black')\n",
    "    ax.set_yticks(np.arange(attention_map.shape[0])+0.5, minor=False)\n",
    "    ax.set_xticks(np.arange(attention_map.shape[1])+0.5, minor=False)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xticklabels(row_labels, minor=False)\n",
    "    ax.set_yticklabels(column_labels, minor=False)\n",
    "\n",
    "    global _idx\n",
    "    _idx += 1\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "np.random.seed(1984)\n",
    "for _ in range(5):\n",
    "    idx = [np.random.randint(0, len(x_test))]\n",
    "    x = x_test[idx]\n",
    "    t = t_test[idx]\n",
    "\n",
    "    model.forward(x, t)\n",
    "    d = model.decoder.attention.attention_weights\n",
    "    d = np.array(d)\n",
    "    attention_map = d.reshape(d.shape[0], d.shape[2])\n",
    "\n",
    "    # 출력하기 위해 반전\n",
    "    attention_map = attention_map[:,::-1]\n",
    "    x = x[:,::-1]\n",
    "\n",
    "    row_labels = [id_to_char[i] for i in x[0]]\n",
    "    column_labels = [id_to_char[i] for i in t[0]]\n",
    "    column_labels = column_labels[1:]\n",
    "\n",
    "    visualize(attention_map, row_labels, column_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
