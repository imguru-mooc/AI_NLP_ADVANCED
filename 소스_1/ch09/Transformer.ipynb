{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(50)\n",
    "a = a.reshape(-1, 1)\n",
    "a.shape\n",
    "a = np.arange(50)[:, np.newaxis]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1)\n"
     ]
    }
   ],
   "source": [
    "position=50\n",
    "# a = tf.range(position, dtype=tf.float32)\n",
    "# print(a)\n",
    "# print(a.numpy())\n",
    "# print(a.shape)\n",
    "\n",
    "a = tf.range(position, dtype=tf.float32)[:, tf.newaxis]\n",
    "print(a.shape)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n",
      "(1, 128)\n",
      "tf.Tensor(\n",
      "[[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "   14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "   28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "   42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "   56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "   70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "   84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "   98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      "  112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
      "  126. 127.]], shape=(1, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "d_model = 128\n",
    "i = tf.range(d_model, dtype=tf.float32)\n",
    "print(i.shape)\n",
    "i = i[tf.newaxis, :]\n",
    "print(i.shape)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.pow(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 2,  4,  8, 16])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = [1,2,3,4]\n",
    "tf.pow(2,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[  256, 65536],\n",
       "       [    9,    27]])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[2, 2], \n",
    "                 [3, 3]])\n",
    "y = tf.constant([[8, 16], \n",
    "                 [2, 3]])\n",
    "tf.pow(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "d_model = 128\n",
    "i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :] # (1,128)\n",
    "i // 2\n",
    "2 * (i // 2)\n",
    "tf.pow(10000,(2 * (i // 2)))\n",
    "(2 * (i // 2)) / tf.cast(d_model, tf.float32)\n",
    "y = tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "i\n",
    "plt.plot(i[0],y[0])  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "d_model=128\n",
    "angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "# print(angles.shape)\n",
    "# print(angles)\n",
    "\n",
    "x = i[0].numpy()\n",
    "# print(x)\n",
    "y = angles[0].numpy()\n",
    "# print(y)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[[ 3]\n",
      " [ 6]\n",
      " [ 9]\n",
      " [12]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,5)\n",
    "# print(a.shape)\n",
    "a = np.arange(1,5).reshape(4,1)\n",
    "# print(a.shape)\n",
    "b = 3\n",
    "c = a*b  # (4,1)*() => (4,1)(4,1)\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[[ 3]\n",
      " [ 6]\n",
      " [ 9]\n",
      " [12]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,5).reshape(4,1)\n",
    "b = np.array([3])\n",
    "c = a*b  # (4,1)*(1,) => (4,1)*(4,1) => (4,1)\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "[[ 3  6  9]\n",
      " [12 15 18]\n",
      " [21 24 27]\n",
      " [30 33 36]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,13).reshape(4,3)\n",
    "b = np.array([[3,],\n",
    "              [3,],\n",
    "              [3,],\n",
    "              [3,]])\n",
    "c = a*b  # (4,3)*(4,1) => (4,3)*(4,3)\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]]\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]]\n",
      "[[0 0 0]\n",
      " [1 2 3]\n",
      " [2 4 6]\n",
      " [3 6 9]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,4).reshape(1,3)\n",
    "print(a)\n",
    "b = np.array([[0],\n",
    "              [1],\n",
    "              [2],\n",
    "              [3]])\n",
    "print(b)\n",
    "c = a*b  # (1,3)*(4,1) => (4,3)(4,3)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.89399666, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.sin(90.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.sin(90.*np.pi/180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.841471, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.sin(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "#         print(\"PositionalEncoding.__init__()\", position, d_model)\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "#         print(\"PositionalEncoding.get_angles()\")\n",
    "#         print(position.shape)  # (50,1)\n",
    "#         print(i.shape)         # (1,128)\n",
    "#         print(d_model)         # 128\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "#         print(angles.shape)  # (1,128)\n",
    "#         print(angles)\n",
    "        return position * angles    #   (50,1)*(1,128) => (50,128)*(50,128) => (50,128)\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "#         print(\"PositionalEncoding.positional_encoding()\", position, d_model)\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],  # (50,1)\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],          # (1,128)\n",
    "            d_model=d_model)\n",
    "\n",
    "#         print(angle_rads[:10,:10])\n",
    "#         print(angle_rads.shape)  # (50,128)\n",
    "        \n",
    "#         print(angle_rads[:10, 0:11:2])\n",
    "#         print(angle_rads[:, 0::2].shape)\n",
    "        \n",
    "        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "#         print(sines[:10,:10])\n",
    "#         print(sines.shape)\n",
    "        \n",
    "        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "#         print(cosines[:10,:10])\n",
    "#         print(cosines.shape)\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "#         print(pos_encoding.shape)\n",
    "#         print(pos_encoding[:10,:10])\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "#         print(pos_encoding.shape)  # (1, 50,128)\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):  # (1,40,128)\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :] # (1,40,128)+(1,40,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.PositionalEncoding object at 0x00000253A4A251F0>\n",
      "(1, 50, 128)\n",
      "tf.Tensor(\n",
      "[[[ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.841471    0.7617204   0.68156135  0.604694    0.53316844\n",
      "    0.46794808  0.40930894  0.35711193  0.3109836   0.27043223]\n",
      "  [ 0.90929747  0.98704624  0.99748     0.9632266   0.9021307\n",
      "    0.82710385  0.7469036   0.6671291   0.5911271   0.52071136]\n",
      "  [ 0.14112     0.5173059   0.7782725   0.9296448   0.9932532\n",
      "    0.9939678   0.95363444  0.8891674   0.8126489   0.732186  ]\n",
      "  [-0.7568025  -0.31671533  0.14153895  0.5176193   0.7784717\n",
      "    0.92974603  0.9932807   0.9939451   0.95358074  0.88909674]\n",
      "  [-0.9589243  -0.9277093  -0.5711271  -0.10512096  0.32393527\n",
      "    0.64936954  0.85889596  0.9676446   0.99994653  0.97975016]\n",
      "  [-0.2794155  -0.8854214  -0.97739613 -0.6850681  -0.23036753\n",
      "    0.21802224  0.5740256   0.81373405  0.9471482   0.9973907 ]\n",
      "  [ 0.6569866  -0.21963017 -0.8593135  -0.98613477 -0.7137213\n",
      "   -0.2640126   0.18858095  0.552511    0.8004216   0.9407037 ]\n",
      "  [ 0.98935825  0.60082203 -0.28022808 -0.88576156 -0.9772618\n",
      "   -0.68466765 -0.22990441  0.21842454  0.5743178   0.81391364]\n",
      "  [ 0.4121185   0.99818236  0.4491935  -0.4248087  -0.93982357\n",
      "   -0.94614553 -0.60810864 -0.14446703  0.29125923  0.6264692 ]]], shape=(1, 10, 10), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 128)\n",
    "print(sample_pos_encoding)\n",
    "print(sample_pos_encoding.pos_encoding.shape)     # (1,50,128)\n",
    "                                                  # (N,T,D)\n",
    "                                            # tf.shape(inputs)[1]\n",
    "print(sample_pos_encoding.pos_encoding[:, :10, :10])\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 128))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 128)\n"
     ]
    }
   ],
   "source": [
    "N=1\n",
    "T=50\n",
    "D=128\n",
    "a = np.arange(N*T*D).reshape(N,T,D)\n",
    "inputs = tf.constant(a, dtype = tf.float32)\n",
    "result = sample_pos_encoding(inputs)\n",
    "print(result.shape)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 2.]\n",
      " [3. 4. 5.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n",
      "(2, 2)\n",
      "matmul_qk= tf.Tensor(\n",
      "[[ 3.  3.]\n",
      " [12. 12.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "query = tf.constant(np.arange(6).reshape(2,3),dtype=tf.float32)\n",
    "print(query)\n",
    "\n",
    "key = tf.constant(np.ones((2,3)),dtype=tf.float32)\n",
    "print(key)\n",
    "\n",
    "matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "print(matmul_qk.shape)\n",
    "print(\"matmul_qk=\", matmul_qk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.  1.  2.]\n",
      "  [ 3.  4.  5.]]\n",
      "\n",
      " [[ 6.  7.  8.]\n",
      "  [ 9. 10. 11.]]], shape=(2, 2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]]], shape=(2, 2, 3), dtype=float32)\n",
      "(2, 2, 2)\n",
      "matmul_qk= tf.Tensor(\n",
      "[[[ 3.  3.]\n",
      "  [12. 12.]]\n",
      "\n",
      " [[21. 21.]\n",
      "  [30. 30.]]], shape=(2, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "query = tf.constant(np.arange(12).reshape(2,2,3),dtype=tf.float32)\n",
    "print(query)\n",
    "\n",
    "key = tf.constant(np.ones((2,2,3)),dtype=tf.float32)\n",
    "print(key)\n",
    "\n",
    "matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "print(matmul_qk.shape)\n",
    "print(\"matmul_qk=\", matmul_qk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 0.  1.  2.  3.]\n",
      "   [ 4.  5.  6.  7.]\n",
      "   [ 8.  9. 10. 11.]]\n",
      "\n",
      "  [[12. 13. 14. 15.]\n",
      "   [16. 17. 18. 19.]\n",
      "   [20. 21. 22. 23.]]]], shape=(1, 2, 3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]]]], shape=(1, 2, 3, 4), dtype=float32)\n",
      "(1, 2, 3, 3)\n",
      "matmul_qk= tf.Tensor(\n",
      "[[[[ 6.  6.  6.]\n",
      "   [22. 22. 22.]\n",
      "   [38. 38. 38.]]\n",
      "\n",
      "  [[54. 54. 54.]\n",
      "   [70. 70. 70.]\n",
      "   [86. 86. 86.]]]], shape=(1, 2, 3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "query = tf.constant(np.arange(24).reshape(1,2,3,4),dtype=tf.float32)\n",
    "print(query)\n",
    "\n",
    "key = tf.constant(np.ones((1,2,3,4)),dtype=tf.float32)\n",
    "print(key)\n",
    "\n",
    "matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "print(matmul_qk.shape)\n",
    "print(\"matmul_qk=\", matmul_qk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 0.  1.  2.  3.]\n",
      "   [ 4.  5.  6.  7.]\n",
      "   [ 8.  9. 10. 11.]]\n",
      "\n",
      "  [[12. 13. 14. 15.]\n",
      "   [16. 17. 18. 19.]\n",
      "   [20. 21. 22. 23.]]]\n",
      "\n",
      "\n",
      " [[[24. 25. 26. 27.]\n",
      "   [28. 29. 30. 31.]\n",
      "   [32. 33. 34. 35.]]\n",
      "\n",
      "  [[36. 37. 38. 39.]\n",
      "   [40. 41. 42. 43.]\n",
      "   [44. 45. 46. 47.]]]], shape=(2, 2, 3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]]\n",
      "\n",
      "  [[1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]]]], shape=(2, 2, 3, 4), dtype=float32)\n",
      "(2, 2, 3, 3)\n",
      "matmul_qk= tf.Tensor(\n",
      "[[[[  6.   6.   6.]\n",
      "   [ 22.  22.  22.]\n",
      "   [ 38.  38.  38.]]\n",
      "\n",
      "  [[ 54.  54.  54.]\n",
      "   [ 70.  70.  70.]\n",
      "   [ 86.  86.  86.]]]\n",
      "\n",
      "\n",
      " [[[102. 102. 102.]\n",
      "   [118. 118. 118.]\n",
      "   [134. 134. 134.]]\n",
      "\n",
      "  [[150. 150. 150.]\n",
      "   [166. 166. 166.]\n",
      "   [182. 182. 182.]]]], shape=(2, 2, 3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "query = tf.constant(np.arange(48).reshape(2,2,3,4),dtype=tf.float32)\n",
    "print(query)\n",
    "\n",
    "key = tf.constant(np.ones((2,2,3,4)),dtype=tf.float32)\n",
    "print(key)\n",
    "\n",
    "matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "print(matmul_qk.shape)\n",
    "print(\"matmul_qk=\", matmul_qk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "\n",
    "    # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True) # (64,4,40,32)(64,4,32,40) =>  (64,4,40,40)\n",
    "#     print(\"matmul_qk.shape =\", matmul_qk.shape)         \n",
    "#     print(\"matmul_qk =\", matmul_qk)\n",
    "    # 스케일링\n",
    "    # dk의 루트값으로 나눠준다.\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "#     print(\"depth=\",depth)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "#     print(\"logits=\",logits)\n",
    "\n",
    "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)  # 1 * (-1000000000)  # (1,4,4,4) += (1,1,1,4)\n",
    "        \n",
    "#     print(\"logits=\",logits)\n",
    "        \n",
    "      \n",
    "\n",
    "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "#     print(\"attention_weights=\",attention_weights)  \n",
    "#     print(\"attention_weights.shape =\",attention_weights.shape)  # (64,4,40,40)\n",
    "\n",
    "    \n",
    "#     print(\"value.shape=\", value.shape)\n",
    "#     print(\"value=\", value)\n",
    "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    output = tf.matmul(attention_weights, value) # (64,4,40,40)(64,4,40,32) => (64,4,40,32)\n",
    "#     print(\"output.shape =\", output.shape) \n",
    "#     print(\"output =\", output) \n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits= tf.Tensor([[ 0.       57.735027  0.        0.      ]], shape=(1, 4), dtype=float32)\n",
      "logits= tf.Tensor([[ 0.       57.735027  0.        0.      ]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits= tf.Tensor([[ 0.        0.       57.735027 57.735027]], shape=(1, 4), dtype=float32)\n",
      "logits= tf.Tensor([[ 0.        0.       57.735027 57.735027]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits= tf.Tensor(\n",
      "[[ 0.        0.       57.735027 57.735027]\n",
      " [ 0.       57.735027  0.        0.      ]\n",
      " [57.735027 57.735027  0.        0.      ]], shape=(3, 4), dtype=float32)\n",
      "logits= tf.Tensor(\n",
      "[[ 0.        0.       57.735027 57.735027]\n",
      " [ 0.       57.735027  0.        0.      ]\n",
      " [57.735027 57.735027  0.        0.      ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], \n",
    "                      [0, 10, 0], \n",
    "                      [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "(1, 3)\n",
      "[<tf.Variable 'dense_30/kernel:0' shape=(3, 4) dtype=float32, numpy=\n",
      "array([[-0.12239695,  0.10106027,  0.10537493, -0.4344296 ],\n",
      "       [ 0.43879783,  0.28196394,  0.3766148 ,  0.39366817],\n",
      "       [ 0.7430475 ,  0.22961569, -0.19613975, -0.6627714 ]],\n",
      "      dtype=float32)>, <tf.Variable 'dense_30/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "dense1 = tf.keras.layers.Dense(4)  # weight = (?,4)  , bias = (4,)\n",
    "# dir(dense1)\n",
    "print(dense1.weights)\n",
    "x = tf.constant([[1,2,3]])\n",
    "print(x.shape)\n",
    "out = dense1(x)   # (1,3)(3,4)+(4,)\n",
    "print(dense1.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAA.__init__()\n",
      "BBB.__init__()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.BBB at 0x253a4a00fa0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AAA():\n",
    "    def __init__(self):\n",
    "        print(\"AAA.__init__()\")\n",
    "\n",
    "class BBB(AAA):\n",
    "    def __init__(self):\n",
    "        super(BBB, self).__init__()\n",
    "        print(\"BBB.__init__()\")        \n",
    "\n",
    "BBB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(5)\n",
    "a = np.reshape(a, (-1,1) )\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        \n",
    "#         print(\"MultiHeadAttention.__init__()\")\n",
    "        self.num_heads = num_heads     # 4\n",
    "        self.d_model = d_model         # 128\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        # d_model을 num_heads로 나눈 값.\n",
    "        # 논문 기준 : 64\n",
    "        self.depth = d_model // self.num_heads  # 32\n",
    "#         print(\"self.depth=\", self.depth)\n",
    "\n",
    "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)  # (?,128)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "#         print(self.query_dense.weights)\n",
    "        # WO에 해당하는 밀집층 정의\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)  # (128,128)\n",
    "\n",
    "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "#         print(\"split_heads()\")\n",
    "#         print(inputs.shape)    # (64, 40, 128) => (64, 40, 4, 32)\n",
    "        inputs = tf.reshape(                                                                                                                     # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))  \n",
    "                # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "#         print(inputs.shape)  # (64, 40, 4, 32)\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "                             # (64, 40, 4, 32)\n",
    "                             # (64, 4, 40, 32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "#         print(\"tf.shape(query) = \", tf.shape(query))\n",
    "#         print(\"batch_size=\", batch_size)\n",
    "\n",
    "#         print(query[0,0,:10])\n",
    "#         print(key[0,0,:10])        \n",
    "        \n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "        # q : (batch_size, query의 문장 길이, d_model)  =>  (64,40,128)\n",
    "        # k : (batch_size, key의 문장 길이, d_model)\n",
    "        # v : (batch_size, value의 문장 길이, d_model)\n",
    "        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "        query = self.query_dense(query)    # (64,40,128)(128,128) => (64,40,128)\n",
    "        key = self.key_dense(key)          # (64,40,128)(128,128) => (64,40,128)\n",
    "        value = self.value_dense(value)    # (64,40,128)(128,128) => (64,40,128)\n",
    "        \n",
    "#         print(self.query_dense.weights)\n",
    "#         print(query.shape)\n",
    "#         print(key.shape)\n",
    "#         print(value.shape)\n",
    "        \n",
    "#         print(query[0,0,:10])\n",
    "#         print(key[0,0,:10])\n",
    "\n",
    "        # 2. 헤드 나누기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "#         print(query.shape)\n",
    "#         print(key.shape)\n",
    "#         print(value.shape)\n",
    "        \n",
    "\n",
    "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "#         print('scaled_attention.shape=',scaled_attention.shape)\n",
    "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "#         print('scaled_attention.shape=',scaled_attention.shape)\n",
    "        \n",
    "        # 4. 헤드 연결(concatenate)하기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "#         print('concat_attention.shape=',concat_attention.shape)  # (64,40,4,32) => (64,40,128)\n",
    "\n",
    "        # 5. WO에 해당하는 밀집층 지나기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        outputs = self.dense(concat_attention)  # (64,40,128)(128,128) => (64,40,128)\n",
    "#         print('outputs.shape=',outputs.shape)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 40, 128)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(np.random.randn(64,40,128))\n",
    "# inputs = { 'query':x, 'key':x, 'value':x, 'mask':None }\n",
    "# mha = MultiHeadAttention(128,4)\n",
    "# mha(inputs)\n",
    "\n",
    "outputs = MultiHeadAttention(128,4)({ 'query':x, 'key':x, 'value':x, 'mask':None })\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "(1, 5)\n",
      "(1, 1, 1, 5)\n",
      "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1, 21, 777, 0, 0]])\n",
    "print(x.shape)\n",
    "mask = tf.cast(tf.math.equal(x, 0), tf.float32)    \n",
    "print(mask.shape)\n",
    "mask = mask[:, tf.newaxis, tf.newaxis, :] \n",
    "print(mask.shape)    \n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n",
      "(2, 5)\n",
      "(2, 1, 1, 5)\n",
      "tf.Tensor(\n",
      "[[[[0. 0. 0. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0. 1.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1, 21, 777, 0, 0],\n",
    "                 [23, 34, 31, 12, 0]])\n",
    "print(x.shape)\n",
    "mask = tf.cast(tf.math.equal(x, 0), tf.float32)    \n",
    "print(mask.shape)\n",
    "mask = mask[:, tf.newaxis, tf.newaxis, :] \n",
    "print(mask.shape)    \n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):  # (1,5)\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32) # (2,5)\n",
    "    # (batch_size, 1, 1, key의 문장 길이)\n",
    "#     print(mask) #  [[0, 0, 0, 1, 1],\n",
    "                #    [1, 1, 0, 0, 0]]  (2,5)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]  # (2,1,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))  # (1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 0. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 0. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0],\n",
    "                                       [0, 0, 777, 23, 25]])))  # (2,1,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.0320586  0.08714432 0.23688284 0.6439142  0.        ], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "logits = tf.constant([1.,2.,3.,4.,-100000000])\n",
    "attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "print(attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits= tf.Tensor(\n",
      "[[[[ 1.1950938  -2.1187646   0.7965206  -0.53906345]\n",
      "   [ 1.5907404   1.2541727   1.7914295   0.7255548 ]\n",
      "   [-0.9760902  -0.7537416   3.0752857   0.51900095]\n",
      "   [-0.2272062  -0.5836903  -0.02214977 -0.05993155]]\n",
      "\n",
      "  [[-0.6097967   0.13491045 -1.7347339  -0.8819026 ]\n",
      "   [ 0.08453563 -1.0859282   0.11162645  1.595788  ]\n",
      "   [-1.1667167   0.6091613   0.2874194   0.60050476]\n",
      "   [ 2.1533718   0.36066413  0.97842664  0.17598261]]\n",
      "\n",
      "  [[ 0.7021263   0.5120816  -0.8397968   1.1962703 ]\n",
      "   [ 0.30637467  1.9412186   0.46160787 -0.0244561 ]\n",
      "   [ 0.14970234 -0.2967584  -0.65657616 -0.54716116]\n",
      "   [-0.35095602  1.1036812  -0.00140379  0.27430826]]\n",
      "\n",
      "  [[-0.31480348  0.08028645  0.7318049  -0.24628524]\n",
      "   [ 0.17853679  1.2193407  -1.0499932   1.2860488 ]\n",
      "   [-1.2800025   1.2097993   0.71407384  0.38002738]\n",
      "   [ 1.1906487  -1.0113816   1.5122131   0.40649387]]]], shape=(1, 4, 4, 4), dtype=float32)\n",
      "logits= tf.Tensor(\n",
      "[[[[ 1.19509375e+00 -2.11876464e+00  7.96520591e-01 -1.00000000e+09]\n",
      "   [ 1.59074044e+00  1.25417268e+00  1.79142952e+00 -1.00000000e+09]\n",
      "   [-9.76090193e-01 -7.53741622e-01  3.07528567e+00 -1.00000000e+09]\n",
      "   [-2.27206200e-01 -5.83690286e-01 -2.21497715e-02 -1.00000000e+09]]\n",
      "\n",
      "  [[-6.09796703e-01  1.34910449e-01 -1.73473394e+00 -1.00000000e+09]\n",
      "   [ 8.45356286e-02 -1.08592820e+00  1.11626446e-01 -1.00000000e+09]\n",
      "   [-1.16671669e+00  6.09161317e-01  2.87419409e-01 -1.00000000e+09]\n",
      "   [ 2.15337181e+00  3.60664129e-01  9.78426635e-01 -1.00000000e+09]]\n",
      "\n",
      "  [[ 7.02126324e-01  5.12081623e-01 -8.39796782e-01 -1.00000000e+09]\n",
      "   [ 3.06374669e-01  1.94121861e+00  4.61607873e-01 -1.00000000e+09]\n",
      "   [ 1.49702340e-01 -2.96758413e-01 -6.56576157e-01 -1.00000000e+09]\n",
      "   [-3.50956023e-01  1.10368121e+00 -1.40378508e-03 -1.00000000e+09]]\n",
      "\n",
      "  [[-3.14803481e-01  8.02864507e-02  7.31804907e-01 -1.00000000e+09]\n",
      "   [ 1.78536788e-01  1.21934068e+00 -1.04999316e+00 -1.00000000e+09]\n",
      "   [-1.28000247e+00  1.20979929e+00  7.14073837e-01 -1.00000000e+09]\n",
      "   [ 1.19064867e+00 -1.01138163e+00  1.51221311e+00 -1.00000000e+09]]]], shape=(1, 4, 4, 4), dtype=float32)\n",
      "attention_weights= tf.Tensor(\n",
      "[[[[0.5855992  0.02130149 0.39309934 0.        ]\n",
      "   [0.34054583 0.24322377 0.41623035 0.        ]\n",
      "   [0.01674327 0.02091246 0.9623443  0.        ]\n",
      "   [0.34156176 0.23913892 0.41929933 0.        ]]\n",
      "\n",
      "  [[0.2915029  0.613854   0.09464307 0.        ]\n",
      "   [0.42777377 0.13270529 0.43952096 0.        ]\n",
      "   [0.08939549 0.5279218  0.38268277 0.        ]\n",
      "   [0.67780775 0.11286089 0.20933138 0.        ]]\n",
      "\n",
      "  [[0.48998198 0.40517697 0.10484107 0.        ]\n",
      "   [0.13705036 0.7028844  0.1600653  0.        ]\n",
      "   [0.4792932  0.3066944  0.21401243 0.        ]\n",
      "   [0.1492234  0.63911337 0.21166329 0.        ]]\n",
      "\n",
      "  [[0.18752952 0.27839094 0.53407955 0.        ]\n",
      "   [0.24247038 0.68655306 0.07097656 0.        ]\n",
      "   [0.04900927 0.5909973  0.35999352 0.        ]\n",
      "   [0.40162864 0.04441145 0.5539599  0.        ]]]], shape=(1, 4, 4, 4), dtype=float32)\n",
      "value.shape= (1, 4, 4, 32)\n",
      "value= tf.Tensor(\n",
      "[[[[ 0.64883727 -1.485892    1.5328394   0.46827772 -0.6769665\n",
      "     0.74803287 -0.92148435 -0.5254221   0.44385305  0.8404297\n",
      "    -2.138074   -1.1688609  -0.32233533 -0.32736272  0.82029504\n",
      "    -0.4285142   1.8515362  -1.9719353  -1.764628    0.78933156\n",
      "    -0.6976118  -0.56422937  0.1760075   1.067821    0.49130356\n",
      "    -0.5306967  -0.16074874 -0.4481589   0.5074094   0.7826995\n",
      "    -1.9957942  -0.07894506]\n",
      "   [-1.4374622  -1.275661   -1.4130063   0.27529716 -0.2802743\n",
      "    -0.8856967   0.2834496  -0.47005233 -1.3693243  -1.5767468\n",
      "    -0.20918754 -0.21424805 -0.4251579  -0.36833033  0.00278387\n",
      "     1.8453127   1.3101182   1.0370901  -1.4219617   0.10072394\n",
      "     1.0115863  -1.6763064  -0.31493974 -0.7312489   0.38439608\n",
      "     3.323385    0.30176204  0.5310373  -0.47229677  0.844129\n",
      "    -0.84424216  1.4455016 ]\n",
      "   [ 0.48017585  0.95918506 -1.3255441   0.25105435  1.6351931\n",
      "    -1.1221607   1.1899563   0.82800204  1.2783021   0.5548854\n",
      "    -0.43416938 -1.0272976   1.2650319  -1.0939604   1.3459073\n",
      "     0.60413736 -0.2303476  -2.5416415   1.0733546  -0.51220465\n",
      "     0.05487275 -0.9032036  -0.9169943  -0.32160535 -1.4097519\n",
      "    -2.980072   -0.3359889  -0.9683737  -0.7375882  -1.4055623\n",
      "     1.3697484  -0.8961499 ]\n",
      "   [ 1.8703365  -0.08678695 -0.30449226  1.1127282   0.7619498\n",
      "    -0.16356823  0.09655845 -0.11079863  0.4955906  -0.11449388\n",
      "     1.0379037   0.8780067  -1.3992941   1.0517304  -0.92330277\n",
      "     0.03752055 -0.12122627 -0.5350873  -0.24063477  1.2563531\n",
      "    -0.75422955  0.85384667 -0.41657043  1.4811673   0.09208634\n",
      "    -1.2217293   1.0621927  -0.07699861  0.8672639  -1.7558088\n",
      "     0.81978464 -0.54997045]]\n",
      "\n",
      "  [[ 0.56824476 -1.3667436  -1.0105847  -0.39787543  0.79550844\n",
      "    -0.40158316 -0.78162706 -2.062097   -1.1776941  -1.4295121\n",
      "    -0.1393954  -0.2482037   0.511208   -0.09715286  0.84980804\n",
      "     0.7462023   0.11396263  1.5797698   0.22616567 -2.6739721\n",
      "    -1.8509585  -1.463409   -1.1059811  -1.2200576   0.02410682\n",
      "    -1.2500789   2.613848    0.0507191  -0.631588    1.4189637\n",
      "    -0.3406181   1.0278784 ]\n",
      "   [ 0.00919319  0.8408695  -0.22988175  0.7353938   0.77311987\n",
      "    -0.9377571   0.55040985  0.14833295  0.17857134 -1.0255306\n",
      "     0.252466    0.57815117  0.7362253   0.22841196  0.2684786\n",
      "    -0.6101735   2.4991045  -1.7601433  -0.39464352  0.4914669\n",
      "    -0.77349395 -1.8321987   0.58763313  0.56160814  0.75886494\n",
      "     1.063314    1.2586926  -0.09792127  0.8240687   0.27595222\n",
      "    -0.45322046 -1.8636161 ]\n",
      "   [ 0.12296107  0.7208222   0.47466874  0.02209537  0.25987917\n",
      "    -1.3943751   0.18936098  0.7626725   1.0727967   0.17310026\n",
      "     0.42795038 -0.39206144  0.7609733   0.13597804 -0.7377059\n",
      "    -0.7895719   0.2654281   1.5709081  -0.18353331 -0.75301754\n",
      "    -1.3908367   2.519713    1.6423779  -0.67712224 -1.1133147\n",
      "    -0.3026904   0.5939217   1.7613198  -0.09180951 -1.3025415\n",
      "     0.6806164  -0.07827005]\n",
      "   [ 0.18679617  0.6928165   0.21993515  0.541359   -0.29975098\n",
      "     1.1375904  -0.8482532  -0.23934826 -0.277591    2.0820208\n",
      "     1.1849931   1.4853712  -1.1452699  -0.07192679 -1.0435605\n",
      "     0.13826759  0.9480853   1.8727845   0.74999267 -0.2516684\n",
      "    -0.11237718 -0.5970925  -0.79736626  1.814856    1.6218251\n",
      "    -0.11532409  0.28219137 -0.26425824 -0.8273112  -1.4732995\n",
      "    -0.42470068 -1.2353107 ]]\n",
      "\n",
      "  [[-2.0040586   1.513696   -0.10090959 -0.5904192  -0.7345605\n",
      "     0.31400645  2.0980885   0.1619681  -1.2248065   1.4119834\n",
      "     1.424025   -0.23069341  0.6708773   0.9442334   1.0691032\n",
      "     0.09310047 -0.02997962  0.3631604  -0.5951521  -1.0304041\n",
      "     0.3119767  -0.29118177  1.987872   -1.0463915  -0.01752109\n",
      "    -0.3999594   0.2433962   1.5335854   0.03614972  0.59701914\n",
      "     0.7812644   1.9048256 ]\n",
      "   [ 2.104973   -0.8564513  -0.2609724  -1.8545358   0.8094475\n",
      "    -0.01943487  0.66348344 -0.4476987   0.13947922 -0.10013211\n",
      "    -0.78455687  0.875979    0.76617825  0.08848763 -1.8110306\n",
      "    -0.36377504  0.23846023 -1.0260264   0.47944754  0.17523935\n",
      "     0.4615437   0.27235562 -1.3765965   0.7515509   0.93794143\n",
      "     0.9816611  -1.6104178   0.31909907  0.07252888  0.3357014\n",
      "     1.5327026   0.4874683 ]\n",
      "   [-0.42588693  0.6805628  -0.2658672   1.1719168   0.33448723\n",
      "     0.5175703   1.4017411   0.13500205  0.01456484 -0.7393059\n",
      "     1.3592293   0.36076766 -1.4681689  -0.51388377  0.03290939\n",
      "     0.6267852  -0.5805964  -0.5820674  -0.15779912  0.96989596\n",
      "     0.00080834  1.8699925  -0.5793061  -0.6245507   1.8850588\n",
      "    -2.1099472  -0.2305624   1.6130688  -0.5081534  -0.74670744\n",
      "    -0.43024045  0.07080629]\n",
      "   [ 0.66204095 -0.5040644  -0.06624489 -0.08858196  2.5923395\n",
      "     1.155305    0.7705233   1.1670842  -0.38987997 -0.26378512\n",
      "     0.5132845   1.0714327  -0.9318232  -1.1089724   0.6026302\n",
      "    -1.3857834  -1.949632    1.594573   -2.1232452   0.06250064\n",
      "     0.7116815   0.19966297  0.8383386  -0.202103    0.19386272\n",
      "    -1.6324643  -0.90925044  0.91584086 -1.0177568  -1.6924343\n",
      "    -0.32612365  0.3048252 ]]\n",
      "\n",
      "  [[-0.96902853 -0.8902097   0.3941771   0.24930581 -0.42580155\n",
      "    -0.3142757  -0.72476184 -1.7213426   2.3474245   2.2698178\n",
      "    -2.0112615  -0.48086286  2.3884223  -1.4401522  -2.2788877\n",
      "    -0.56152135 -0.25946733  2.6871278   1.4679143  -0.3149124\n",
      "     1.2064239  -0.6278533   1.1471837   0.56910896  1.3419912\n",
      "    -0.19587982 -0.788592   -1.3970934   1.2267638   0.95406544\n",
      "    -1.7518954   0.09745122]\n",
      "   [ 0.16486944  0.42888674  0.17242755  0.02424308  0.537511\n",
      "     1.4060081   0.64943314 -0.43307817 -0.25545245  0.11400468\n",
      "     0.11465883 -0.71755517 -0.5515097   0.96317637 -0.62430555\n",
      "    -0.95685345 -1.9614505   1.2241138   0.06095259  2.6140578\n",
      "    -1.278278    0.02951697  1.1851577   0.74659616  0.59714323\n",
      "     0.16923071  0.7701919   0.7200749  -0.0879586   1.489058\n",
      "    -0.20844685 -1.0539527 ]\n",
      "   [ 1.1525077  -1.0704871   0.16739799  0.33818483 -0.30377683\n",
      "    -1.9638548  -1.8698537  -0.29772294 -0.3896265   0.01106519\n",
      "    -0.09590802 -0.71291274  0.6503527   0.8209613  -0.7933652\n",
      "    -0.09217893  0.25786546  0.82986397  0.8172591   0.33302894\n",
      "    -0.7054438   0.44397384  0.5484835  -0.565721   -3.22361\n",
      "    -2.0528266   0.73467714 -1.7187022   0.16787966  0.9590669\n",
      "     0.5225389   1.099211  ]\n",
      "   [ 0.8555119  -2.67447    -2.2666197   0.0666431   1.5045979\n",
      "     0.16962086 -0.15441382  1.1176894   0.7149976   0.07062009\n",
      "    -0.1656506  -0.23238806 -0.82167244  0.6222929  -0.25629067\n",
      "     0.47949237 -0.81355053  1.7436947   0.20567386  1.4591503\n",
      "    -1.5454756   0.40216407 -0.29164064  1.8046491  -0.45715207\n",
      "     0.37054017  0.25644913 -0.88397396  1.6646262  -0.31255877\n",
      "     0.36856014 -0.6907793 ]]]], shape=(1, 4, 4, 32), dtype=float32)\n",
      "output = tf.Tensor(\n",
      "[[[[ 0.5380953  -0.52025557  0.3464598   0.37877658  0.24039206\n",
      "    -0.02193984 -0.06581154  0.0077875   0.73325104  0.67669296\n",
      "    -1.4271821  -1.0928779   0.2994674  -0.62958443  1.0094987\n",
      "     0.02585632  1.0216161  -2.1317897  -0.6417197   0.26303017\n",
      "    -0.36540216 -0.7211689  -0.2641087   0.48331556 -0.25827733\n",
      "    -1.4114468  -0.21978337 -0.63179666 -0.00286758 -0.07619616\n",
      "    -0.6482719  -0.36771473]\n",
      "   [ 0.0711976  -0.4170435  -0.37340632  0.3309253   0.3819095\n",
      "    -0.42776036  0.25042996  0.05138135  0.35016823  0.13366269\n",
      "    -0.959706   -0.8777534   0.31336623 -0.6564082   0.8402326\n",
      "     0.5543555   0.8533071  -1.4771976  -0.50002885  0.08010691\n",
      "     0.03131274 -0.97580427 -0.39834306  0.05192298 -0.32597584\n",
      "    -0.61279666 -0.12119539 -0.4265243  -0.24908423 -0.1131804\n",
      "    -0.31486833 -0.04830882]\n",
      "   [ 0.44289726  0.8715104  -1.2795144   0.25519836  1.556423\n",
      "    -1.0859025   1.1356467   0.7781958   1.2089623   0.5150887\n",
      "    -0.4579934  -1.012665    1.2031082  -1.0659504   1.3090189\n",
      "     0.6128034  -0.16327514 -2.4572625   0.9736543  -0.47759482\n",
      "     0.06228093 -0.9136956  -0.88610345 -0.30690846 -1.340402\n",
      "    -2.8072407  -0.31971788 -0.92830724 -0.71119505 -1.321877\n",
      "     1.2670982  -0.8334975 ]\n",
      "   [ 0.07920225 -0.4103984  -0.37014526  0.33104697  0.38738504\n",
      "    -0.42682636  0.2519879   0.05530879  0.36013567  0.14266022\n",
      "    -0.9623561  -0.88121843  0.31865782 -0.65859354  0.84518516\n",
      "     0.54823637  0.8491296  -1.4912376  -0.49271896  0.07892543\n",
      "     0.02664024 -0.97230196 -0.399692    0.05500786 -0.33137345\n",
      "    -0.63605726 -0.12362251 -0.43212074 -0.24890316 -0.12014702\n",
      "    -0.30924362 -0.05704397]]\n",
      "\n",
      "  [[ 0.18292569  0.18598223 -0.3907781   0.33753374  0.7310715\n",
      "    -0.8246765   0.12794644 -0.43787077 -0.13215174 -1.0298502\n",
      "     0.15484564  0.2454424   0.6729743   0.12476064  0.34270942\n",
      "    -0.23176484  1.5924267  -0.47128785 -0.19369572 -0.5490496\n",
      "    -1.1460052  -1.312817    0.19376393 -0.07498986  0.36749196\n",
      "     0.25967035  1.5908082   0.12137211  0.31305903  0.45974988\n",
      "    -0.3130867  -0.8517663 ]\n",
      "   [ 0.29834417 -0.15625277 -0.25418133 -0.06289865  0.55711704\n",
      "    -0.9090891  -0.17808914 -0.52721596 -0.00857261 -0.67151994\n",
      "     0.16196704 -0.20177053  0.65084606  0.04851723  0.07491693\n",
      "    -0.10880087  0.49705583  1.1326509  -0.03629028 -1.4096018\n",
      "    -1.5057402   0.23831618  0.32673174 -0.7449897  -0.37830752\n",
      "    -0.5266824   1.5462118   0.7828386  -0.20117068  0.07112151\n",
      "     0.09329292  0.15798637]\n",
      "   [ 0.10270689  0.5975789  -0.03005375  0.36111766  0.578713\n",
      "    -1.0645654   0.2931646   0.18582764  0.399532   -0.6029494\n",
      "     0.28459024  0.13299517  0.72558045  0.16393508 -0.06460261\n",
      "    -0.55757236  1.4310943  -0.18683422 -0.25835776 -0.26775178\n",
      "    -1.106061   -0.13382906  0.8398643  -0.07170549 -0.02326998\n",
      "     0.3337608   1.1254411   0.626866    0.3434488  -0.22593004\n",
      "    -0.00925452 -0.92190844]\n",
      "   [ 0.41193783 -0.6805974  -0.6115637  -0.18206057  0.68085766\n",
      "    -0.6699187  -0.42803395 -1.221313   -0.5535265  -1.0484414\n",
      "     0.02359369 -0.1850545   0.5888874  -0.01160771  0.4518822\n",
      "     0.27163482  0.41485834  1.2009693   0.07033774 -1.9146019\n",
      "    -1.633037   -0.67123854 -0.33952054 -0.90532386 -0.13106576\n",
      "    -0.7906692   2.03807     0.3920258  -0.35430872  0.7202659\n",
      "    -0.13955007  0.46999025]]\n",
      "\n",
      "  [[-0.17371643  0.46602032 -0.1830577  -0.91784495  0.00311609\n",
      "     0.20024556  1.4438138  -0.087882   -0.5420923   0.5737656\n",
      "     0.52236533  0.27971417  0.4852311   0.44463438 -0.20649631\n",
      "    -0.03606289  0.02105877 -0.29880476 -0.11389651 -0.33219153\n",
      "     0.3399546   0.16373041  0.35552117 -0.2736804   0.5690788\n",
      "    -0.01943554 -0.5574169   1.0498366  -0.0061756   0.3502615\n",
      "     0.95871437  1.1382645 ]\n",
      "   [ 1.136726   -0.28559914 -0.23981923 -1.1968582   0.5218161\n",
      "     0.11221927  0.978266   -0.2708735  -0.06749109  0.00479431\n",
      "    -0.13872418  0.64184177  0.3954758   0.10934914 -1.1211566\n",
      "    -0.14260578  0.07056793 -0.7645754   0.23017223  0.13720244\n",
      "     0.36729777  0.45084885 -0.78787637  0.28487617  0.9585956\n",
      "     0.29745033 -1.135485    0.6926645  -0.02540397  0.19825903\n",
      "     1.1155187   0.6150245 ]\n",
      "   [-0.4060933   0.60848427 -0.18530294 -0.60095483 -0.03223241\n",
      "     0.25530708  1.5090762  -0.03078437 -0.5411469   0.48782337\n",
      "     0.73279834  0.23529682  0.24232307  0.3697258  -0.03597598\n",
      "     0.06719448 -0.06548946 -0.26518586 -0.17197944 -0.23255096\n",
      "     0.2912542   0.34417015  0.4066004  -0.40469348  0.68268967\n",
      "    -0.3421828  -0.42659122  1.1781198  -0.06918062  0.22930029\n",
      "     0.7524493   1.0776272 ]\n",
      "   [ 0.9561193  -0.17744045 -0.23812336 -1.0253112   0.4785138\n",
      "     0.14398667  1.0338222  -0.23338583 -0.09054393 -0.00977874\n",
      "    -0.00122398  0.6017864   0.27902788  0.08868501 -0.99095297\n",
      "    -0.0859333   0.02503852 -0.72475743  0.18421043  0.16352879\n",
      "     0.3417041   0.52642375 -0.70578206  0.19198567  0.9958341\n",
      "     0.12111101 -1.0417207   0.77421474 -0.05580885  0.14558993\n",
      "     1.0050875   0.61077917]]\n",
      "\n",
      "  [[ 0.47970748 -0.6192677   0.21132594  0.23411885 -0.09245317\n",
      "    -0.71637076 -0.9537686  -0.6023753   0.1610042   0.46330538\n",
      "    -0.3964734  -0.670689    0.64170444  0.4365272  -1.0248798\n",
      "    -0.42091203 -0.45698717  1.2879113   0.7287272   0.8465386\n",
      "    -0.506384    0.12759358  0.8380018   0.01243034 -1.303762\n",
      "    -1.0859936   0.4589062  -0.9794576   0.29522866  1.1056738\n",
      "    -0.10748446  0.3119302 ]\n",
      "   [-0.03996807  0.00262453  0.22583827  0.10109663  0.24422452\n",
      "     0.74970895  0.13742124 -0.73583704  0.3661449   0.6294192\n",
      "    -0.41575918 -0.6598348   0.2466408   0.37034643 -1.0374919\n",
      "    -0.7996255  -1.3912506   1.5508689   0.4557792   1.7419698\n",
      "    -0.6351536  -0.10045911  1.1307611   0.61041707  0.5065629\n",
      "    -0.07701176  0.38971224  0.03362828  0.2489812   1.3217212\n",
      "    -0.5308045  -0.6219472 ]\n",
      "   [ 0.4648413  -0.17552607  0.18148474  0.14829025  0.18744165\n",
      "     0.10856956 -0.32484207 -0.44748807 -0.17618917  0.18260197\n",
      "    -0.06533367 -0.70428383  0.02523687  0.7941946  -0.76625586\n",
      "    -0.62620133 -1.0790982   1.1538877   0.4021722   1.6493556\n",
      "    -0.95028806  0.14650153  0.9540981   0.265472   -0.7417987\n",
      "    -0.64858925  0.68101203 -0.2616299   0.0685751   1.2720451\n",
      "    -0.02094002 -0.22239837]\n",
      "   [ 0.25657555 -0.93149316  0.25870234  0.28854585 -0.31542265\n",
      "    -1.151676   -1.2980669  -0.87550074  0.7156104   0.92281663\n",
      "    -0.85581726 -0.6199211   1.2950348  -0.08085063 -1.3824854\n",
      "    -0.31908172 -0.04847327  1.5933034   1.0449922   0.17410094\n",
      "     0.03697664 -0.00490926  0.81721425 -0.05165887 -1.2202485\n",
      "    -1.2083389   0.12446588 -1.4812253   0.58179575  0.9805959\n",
      "    -0.4234032   0.6012504 ]]]], shape=(1, 4, 4, 32), dtype=float32)\n",
      "(1, 4, 128)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(np.random.randn(1,4,128))\n",
    "\n",
    "mask = create_padding_mask(tf.constant([[1, 23, 777, 0]]))  # (1,1,1,4)\n",
    "\n",
    "outputs = MultiHeadAttention(128,4)({ 'query':x, 'key':x, 'value':x, 'mask':mask })\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.]\n",
      " [ 3.  4.]\n",
      " [ 5.  6.]\n",
      " [ 7.  8.]\n",
      " [ 9. 10.]]\n",
      "tf.Tensor(\n",
      "[[ 1.25  2.5 ]\n",
      " [ 3.75  5.  ]\n",
      " [ 6.25  7.5 ]\n",
      " [ 8.75  0.  ]\n",
      " [11.25 12.5 ]], shape=(5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf.random.set_seed(1)\n",
    "layer = tf.keras.layers.Dropout(.2, input_shape=(2,))\n",
    "data = np.arange(1, 11).reshape(5, 2).astype(np.float32)\n",
    "print(data)\n",
    "\n",
    "outputs = layer(data, training=True)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  0.  10.  20.  30.]\n",
      " [ 40.  50.  60.  70.]\n",
      " [ 80.  90. 100. 110.]\n",
      " [120. 130. 140. 150.]\n",
      " [160. 170. 180. 190.]\n",
      " [200. 210. 220. 230.]\n",
      " [240. 250. 260. 270.]\n",
      " [280. 290. 300. 310.]], shape=(8, 4), dtype=float32)\n",
      "[ 15.  55.  95. 135. 175. 215. 255. 295.] [11.18034 11.18034 11.18034 11.18034 11.18034 11.18034 11.18034 11.18034]\n",
      "<tf.Variable 'layer_normalization_11/beta:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>\n",
      "<tf.Variable 'layer_normalization_11/gamma:0' shape=(4,) dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>\n",
      "tf.Tensor(\n",
      "[[-1.3416353  -0.44721177  0.4472118   1.3416353 ]\n",
      " [-1.3416353  -0.44721177  0.4472118   1.3416353 ]\n",
      " [-1.341635   -0.4472114   0.44721216  1.3416357 ]\n",
      " [-1.3416356  -0.447212    0.44721156  1.3416351 ]\n",
      " [-1.3416352  -0.44721165  0.44721192  1.3416355 ]\n",
      " [-1.3416349  -0.4472113   0.44721228  1.3416358 ]\n",
      " [-1.3416345  -0.44721094  0.44721264  1.3416362 ]\n",
      " [-1.3416361  -0.4472125   0.4472111   1.3416346 ]], shape=(8, 4), dtype=float32)\n",
      "[ 0.00000003  0.00000003  0.00000036 -0.00000021  0.00000012  0.00000051\n",
      "  0.00000083 -0.00000069] [0.99999595 0.99999595 0.99999595 0.99999595 0.99999595 0.99999595\n",
      " 0.99999595 0.99999595]\n"
     ]
    }
   ],
   "source": [
    "data = tf.constant(np.arange(32).reshape(8, 4) * 10, dtype=tf.float32)\n",
    "print(data)\n",
    "\n",
    "m = np.mean(data.numpy(), axis=1)\n",
    "s = np.std(data.numpy(), axis=1)\n",
    "print(m, s)\n",
    "\n",
    "layer = tf.keras.layers.LayerNormalization(axis=1)\n",
    "\n",
    "output = layer(data)\n",
    "print(layer.beta)\n",
    "print(layer.gamma)\n",
    "print(output)\n",
    "\n",
    "m = np.mean(output.numpy(), axis=1)\n",
    "s = np.std(output.numpy(), axis=1)\n",
    "print(m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744.2\n",
      "697530.5599999999\n",
      "[ 0.43918521  1.76703799 -0.53185952 -0.84316855 -0.83119513]\n",
      "0.0\n",
      "0.9999999999999283\n",
      "[3.87837042 6.53407598 1.93628097 1.31366289 1.33760974]\n",
      "2.9999999999999996\n",
      "1.9999999999998566\n"
     ]
    }
   ],
   "source": [
    "x_i = np.array([1111,2220,300,40,50])\n",
    "k = len(x_i)\n",
    "mean_i = sum(x_i[j] for j in range(k)) / k\n",
    "print(mean_i)\n",
    "var_i = sum((x_i[j] - mean_i) ** 2 for j in range(k)) / k\n",
    "print(var_i)\n",
    "\n",
    "x_i_normalized = (x_i - mean_i) / np.sqrt(var_i + 0.0000001)\n",
    "print(x_i_normalized)\n",
    "print(np.mean(x_i_normalized))\n",
    "print(np.std(x_i_normalized))\n",
    "\n",
    "gamma=2\n",
    "beta=3\n",
    "\n",
    "output_i = x_i_normalized * gamma + beta\n",
    "print(output_i)\n",
    "print(np.mean(output_i))\n",
    "print(np.std(output_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")   # (None,None,128)\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")  # (None,1,1,None)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': padding_mask # 패딩 마스크 사용\n",
    "        })       \n",
    "    \n",
    "#     print('attention.shape=', attention.shape)  # (64,40,128)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "#     print('attention.shape=', attention.shape)  # (64,40,128)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)  # (64,40,128) + (64,40,128)\n",
    "    \n",
    "#     print('attention.shape=', attention.shape)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)  # (64,40,128)(128,512)=>(64,40,512)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)  # (64,40,512)(512,128)=>(64,40,128)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)  # (64,40,128) + (64,40,128)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "#     print(\"inputs.shape=\",inputs.shape)  # (None,None)\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\") # (None,1,1,None)\n",
    "#     print(\"padding_mask.shape=\",padding_mask.shape)\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃                                          # (N,T)\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)   # (9000,128) => (N,T,D)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))              # (64,40,128)\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)      # (64,40,128)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 인코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "          dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "      )([outputs, padding_mask])\n",
    "#         print('outputs.shape=',outputs.shape)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 40)\n",
      "(64, 1, 1, 40)\n",
      "(64, 40, 128)\n"
     ]
    }
   ],
   "source": [
    "# 인코더의 테스트\n",
    "\n",
    "# 인코더의 입력\n",
    "x = tf.constant(np.arange(64*40).reshape(64,40))  # (N,T)\n",
    "print(x.shape)\n",
    "\n",
    "# 인코더의 패딩 마스크\n",
    "enc_padding_mask = tf.keras.layers.Lambda(\n",
    "    create_padding_mask, output_shape=(1, 1, 40),\n",
    "    name='enc_padding_mask')(x)\n",
    "\n",
    "print(enc_padding_mask.shape)\n",
    "\n",
    "# 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "enc_outputs = encoder(vocab_size=9000, num_layers=2, dff=512,\n",
    "    d_model=128, num_heads=4, dropout=0.2,)(inputs=[x, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "print(enc_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=5\n",
    "a = tf.ones((seq_len, seq_len))\n",
    "print(a)\n",
    "print(tf.linalg.band_part(a, -1, 0))\n",
    "print(1-tf.linalg.band_part(a, -1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    print(seq_len)  # 5\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n",
    "#     return look_ahead_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[5, 4, 1, 0, 0]])))  # (N,T) => (1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "        })\n",
    "\n",
    "    # 잔차 연결과 층 정규화\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "            'mask': padding_mask # 패딩 마스크\n",
    "        })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                  d_model, num_heads, dropout,\n",
    "                  name=\"transformer\"):\n",
    "\n",
    "    # 인코더의 입력\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 디코더의 입력\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더의 패딩 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 디코더의 패딩 마스크(두번째 서브층)\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 다음 단어 예측을 위한 출력층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_transformer = transformer(\n",
    "    vocab_size = 9000,\n",
    "    num_layers = 4,\n",
    "    dff = 512,\n",
    "    d_model = 128,\n",
    "    num_heads = 4,\n",
    "    dropout = 0.3,\n",
    "    name=\"small_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    small_transformer, to_file='small_transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "# Text(0.5, 0, 'Train Step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow_datasets 처음 설치 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow_datasets 업그레이드 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --user --upgrade tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfds.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\", filename=\"ChatBotData.csv\")\n",
    "train_data = pd.read_csv('ChatBotData.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('챗봇 샘플의 개수 :', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = re.sub(r\"([?.!,])\", r\" \\1 \", \"   12시 땡!    \")\n",
    "sentence = sentence.strip()\n",
    "print(\"[%s]\"%sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)\n",
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])\n",
    "print(len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더를 사용하여 질문, 답변 데이터로부터 단어 집합(Vocabulary) 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)\n",
    "print(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
    "print(questions[20])\n",
    "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
    "# 임의의 입력 문장을 sample_string에 저장\n",
    "sample_string = questions[20]\n",
    "\n",
    "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "#     print(sentence1)\n",
    "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "\n",
    "    tokenized_inputs.append(sentence1)\n",
    "    tokenized_outputs.append(sentence2)\n",
    "\n",
    "  # 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "  print(tokenized_inputs[0])\n",
    "\n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)\n",
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"날씨가 좋넹.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"고민이 있어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"너무 화가나\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"카페갈래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"게임하고싶당\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"게임하자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
