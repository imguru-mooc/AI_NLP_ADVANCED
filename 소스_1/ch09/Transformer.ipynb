{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(50)\n",
    "a = a.reshape(-1, 1)\n",
    "a.shape\n",
    "a = np.arange(50)[:, np.newaxis]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position=50\n",
    "# a = tf.range(position, dtype=tf.float32)\n",
    "# print(a)\n",
    "# print(a.numpy())\n",
    "# print(a.shape)\n",
    "\n",
    "a = tf.range(position, dtype=tf.float32)[:, tf.newaxis]\n",
    "print(a.shape)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 128\n",
    "i = tf.range(d_model, dtype=tf.float32)\n",
    "print(i.shape)\n",
    "i = i[tf.newaxis, :]\n",
    "print(i.shape)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.pow(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = [1,2,3,4]\n",
    "tf.pow(2,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[2, 2], \n",
    "                 [3, 3]])\n",
    "y = tf.constant([[8, 16], \n",
    "                 [2, 3]])\n",
    "tf.pow(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_model = 128\n",
    "i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :] # (1,128)\n",
    "i // 2\n",
    "2 * (i // 2)\n",
    "tf.pow(10000,(2 * (i // 2)))\n",
    "(2 * (i // 2)) / tf.cast(d_model, tf.float32)\n",
    "y = tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "i\n",
    "plt.plot(i[0],y[0])  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "d_model=128\n",
    "angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "# print(angles.shape)\n",
    "# print(angles)\n",
    "\n",
    "x = i[0].numpy()\n",
    "# print(x)\n",
    "y = angles[0].numpy()\n",
    "# print(y)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[[ 3]\n",
      " [ 6]\n",
      " [ 9]\n",
      " [12]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,5)\n",
    "# print(a.shape)\n",
    "a = np.arange(1,5).reshape(4,1)\n",
    "# print(a.shape)\n",
    "b = 3\n",
    "c = a*b  # (4,1)*() => (4,1)(4,1)\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[[ 3]\n",
      " [ 6]\n",
      " [ 9]\n",
      " [12]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,5).reshape(4,1)\n",
    "b = np.array([3])\n",
    "c = a*b  # (4,1)*(1,) => (4,1)*(4,1) => (4,1)\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "[[ 3  6  9]\n",
      " [12 15 18]\n",
      " [21 24 27]\n",
      " [30 33 36]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,13).reshape(4,3)\n",
    "b = np.array([[3,],\n",
    "              [3,],\n",
    "              [3,],\n",
    "              [3,]])\n",
    "c = a*b  # (4,3)*(4,1) => (4,3)*(4,3)\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]]\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]]\n",
      "[[0 0 0]\n",
      " [1 2 3]\n",
      " [2 4 6]\n",
      " [3 6 9]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,4).reshape(1,3)\n",
    "print(a)\n",
    "b = np.array([[0],\n",
    "              [1],\n",
    "              [2],\n",
    "              [3]])\n",
    "print(b)\n",
    "c = a*b  # (1,3)*(4,1) => (4,3)(4,3)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.89399666, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.sin(90.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.sin(90.*np.pi/180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.84147096, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.sin(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "#         print(\"PositionalEncoding.__init__()\", position, d_model)\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "#         print(\"PositionalEncoding.get_angles()\")\n",
    "#         print(position.shape)  # (50,1)\n",
    "#         print(i.shape)         # (1,128)\n",
    "#         print(d_model)         # 128\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "#         print(angles.shape)  # (1,128)\n",
    "#         print(angles)\n",
    "        return position * angles    #   (50,1)*(1,128) => (50,128)*(50,128) => (50,128)\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "#         print(\"PositionalEncoding.positional_encoding()\", position, d_model)\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],  # (50,1)\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],          # (1,128)\n",
    "            d_model=d_model)\n",
    "\n",
    "#         print(angle_rads[:10,:10])\n",
    "#         print(angle_rads.shape)  # (50,128)\n",
    "        \n",
    "#         print(angle_rads[:10, 0:11:2])\n",
    "#         print(angle_rads[:, 0::2].shape)\n",
    "        \n",
    "        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "#         print(sines[:10,:10])\n",
    "#         print(sines.shape)\n",
    "        \n",
    "        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "#         print(cosines[:10,:10])\n",
    "#         print(cosines.shape)\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "#         print(pos_encoding.shape)\n",
    "        print(pos_encoding[:10,:10])\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "#         print(pos_encoding.shape)  # (1, 50,128)\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):  # (1,40,128)\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :] # (1,40,128)+(1,40,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.84147096  0.7617204   0.68156135  0.604694    0.53316844  0.46794808\n",
      "   0.40930894  0.35711196  0.3109836   0.27043223]\n",
      " [ 0.9092974   0.98704624  0.99748     0.9632266   0.9021307   0.82710385\n",
      "   0.74690354  0.66712916  0.5911271   0.52071136]\n",
      " [ 0.14112     0.51730573  0.7782725   0.9296448   0.9932532   0.9939678\n",
      "   0.95363444  0.8891674   0.8126489   0.732186  ]\n",
      " [-0.7568025  -0.31671554  0.14153895  0.5176193   0.7784717   0.92974603\n",
      "   0.9932807   0.9939451   0.95358074  0.8890967 ]\n",
      " [-0.9589243  -0.9277093  -0.5711271  -0.10512096  0.32393527  0.64936954\n",
      "   0.85889596  0.9676445   0.99994653  0.97975016]\n",
      " [-0.2794155  -0.88542116 -0.97739613 -0.6850681  -0.23036753  0.21802224\n",
      "   0.5740256   0.81373405  0.9471482   0.9973907 ]\n",
      " [ 0.6569866  -0.2196297  -0.8593135  -0.98613477 -0.7137213  -0.2640126\n",
      "   0.18858095  0.5525108   0.8004216   0.9407037 ]\n",
      " [ 0.98935825  0.6008224  -0.28022808 -0.88576156 -0.9772618  -0.6846676\n",
      "  -0.22990441  0.2184243   0.5743178   0.8139136 ]\n",
      " [ 0.41211846  0.99818236  0.4491935  -0.4248087  -0.9398235  -0.94614553\n",
      "  -0.6081086  -0.14446725  0.29125923  0.6264692 ]], shape=(10, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 128)\n",
    "# print(sample_pos_encoding.pos_encoding.shape)     # (1,50,128)\n",
    "                                                   # (N,T,D)\n",
    "                                            # tf.shape(inputs)[1]\n",
    "# print(sample_pos_encoding.pos_encoding[:, :10, :10])\n",
    "\n",
    "# plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "# plt.xlabel('Depth')\n",
    "# plt.xlim((0, 128))\n",
    "# plt.ylabel('Position')\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(8).reshape(2,2,2)\n",
    "print(x)\n",
    "w = np.ones((2,3))\n",
    "print(w)   \n",
    "out = np.dot(x,w)    # (2,2,2)(2,3)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(12).reshape(2,3,2)\n",
    "print(x)\n",
    "w = np.ones((2,3))\n",
    "print(w)   \n",
    "out = np.dot(w,x)    # (2,3)(2,2,2)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = tf.constant(np.arange(24).reshape(1,2,3,4),dtype=tf.float32)\n",
    "print(query)\n",
    "\n",
    "key = tf.constant(np.ones((1,2,3,4)),dtype=tf.float32)\n",
    "print(key)\n",
    "\n",
    "matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "print(matmul_qk.shape)\n",
    "print(\"matmul_qk=\", matmul_qk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "    # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True) # (1,4,4,32)(1,4,32,4) => (4,32)(32,4)\n",
    "#     print(\"matmul_qk.shape =\", matmul_qk.shape)         # (1,4,4,4)\n",
    "#     print(\"matmul_qk =\", matmul_qk)\n",
    "    # 스케일링\n",
    "    # dk의 루트값으로 나눠준다.\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "#     print(\"depth=\",depth)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "#     print(\"logits=\",logits)\n",
    "\n",
    "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)  # 1 * (-1000000000)  # (1,4,4,4) += (1,1,1,4)\n",
    "        \n",
    "      \n",
    "\n",
    "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "#     print(\"attention_weights=\",attention_weights)  \n",
    "#     print(\"attention_weights.shape =\",attention_weights.shape)  # (1,4,4,4)\n",
    "#     print(\"attention_weights =\",attention_weights)\n",
    "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    output = tf.matmul(attention_weights, value) # (1,4,4,4)(1,4,4,32) => (1,4,4,32)\n",
    "#     print(\"output.shape =\", output.shape) \n",
    "#     print(\"output =\", output) \n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], \n",
    "                      [0, 10, 0], \n",
    "                      [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = tf.keras.layers.Dense(4)  # weight = (?,4)  , bias = (4,)\n",
    "# dir(dense1)\n",
    "print(dense1.weights)\n",
    "x = tf.constant([[1,2,3]])\n",
    "print(x.shape)\n",
    "out = dense1(x)   # (1,3)(3,4)+(4,)\n",
    "print(dense1.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        \n",
    "#         print(\"MultiHeadAttention.__init__()\")\n",
    "        self.num_heads = num_heads     # 4\n",
    "        self.d_model = d_model         # 128\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        # d_model을 num_heads로 나눈 값.\n",
    "        # 논문 기준 : 64\n",
    "        self.depth = d_model // self.num_heads  # 32\n",
    "#         print(\"self.depth=\", self.depth)\n",
    "\n",
    "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)  # (?,128)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "#         print(self.query_dense.weights)\n",
    "        # WO에 해당하는 밀집층 정의\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)  # (128,128)\n",
    "\n",
    "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "#         print(\"split_heads()\")\n",
    "#         print(inputs.shape)\n",
    "        inputs = tf.reshape(                                             # (1,4,128)\n",
    "                                                                         # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))  # (1,4,4,32)\n",
    "                                                                         # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "#         print(inputs.shape)                                              # (1,4,4,32)\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "#         print(\"batch_size=\", batch_size)\n",
    "\n",
    "#         print(query[0,0,:10])\n",
    "#         print(key[0,0,:10])        \n",
    "        \n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "        # q : (batch_size, query의 문장 길이, d_model)  =>  (1,4,128)\n",
    "        # k : (batch_size, key의 문장 길이, d_model)\n",
    "        # v : (batch_size, value의 문장 길이, d_model)\n",
    "        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "        query = self.query_dense(query)    # (1,4,128)(128,128) => (1,4,128)\n",
    "        key = self.key_dense(key)          # (1,4,128)(128,128) => (1,4,128)\n",
    "        value = self.value_dense(value)    # (1,4,128)(128,128) => (1,4,128)\n",
    "        \n",
    "#         print(self.query_dense.weights)\n",
    "#         print(query.shape)\n",
    "#         print(key.shape)\n",
    "#         print(value.shape)\n",
    "        \n",
    "#         print(query[0,0,:10])\n",
    "#         print(key[0,0,:10])\n",
    "\n",
    "        # 2. 헤드 나누기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "#         print(query.shape)\n",
    "#         print(key.shape)\n",
    "#         print(value.shape)\n",
    "        \n",
    "\n",
    "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "#         print('scaled_attention.shape=',scaled_attention.shape)\n",
    "        \n",
    "        # 4. 헤드 연결(concatenate)하기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "#         print('concat_attention.shape=',concat_attention.shape)  # (1,4,128)\n",
    "\n",
    "        # 5. WO에 해당하는 밀집층 지나기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        outputs = self.dense(concat_attention)  # (1,4,128)(128,128) => (1,4,128)\n",
    "#         print('outputs.shape=',outputs.shape)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mha = MultiHeadAttention(128,4)\n",
    "x = tf.constant(np.random.randn(64,40,128))\n",
    "# inputs = { 'query':x, 'key':x, 'value':x, 'mask':None }\n",
    "# mha(inputs)\n",
    "\n",
    "outputs = MultiHeadAttention(128,4)({ 'query':x, 'key':x, 'value':x, 'mask':None })\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):  # (2,5)\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32) # (2,5)\n",
    "    # (batch_size, 1, 1, key의 문장 길이)\n",
    "#     print(mask) #  [[0, 0, 0, 1, 1],\n",
    "                #   [1, 1, 0, 0, 0]]  (2,5)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]  # (2,1,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))  # (1,1,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0],\n",
    "                                       [0, 0, 777, 23, 25]])))  # (2,1,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(np.random.randn(1,4,128))\n",
    "\n",
    "mask = create_padding_mask(tf.constant([[1, 0, 777, 0]]))  # (1,1,1,4)\n",
    "\n",
    "outputs = MultiHeadAttention(128,4)({ 'query':x, 'key':x, 'value':x, 'mask':mask })\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")   # (None,None,128)\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")  # (None,1,1,None)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': padding_mask # 패딩 마스크 사용\n",
    "        })       \n",
    "    \n",
    "#     print('attention.shape=', attention.shape)  # (64,40,128)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "#     print('attention.shape=', attention.shape)  # (64,40,128)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)  # (64,40,128) + (64,40,128)\n",
    "    \n",
    "#     print('attention.shape=', attention.shape)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)  # (64,40,128)(128,512)=>(64,40,512)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)  # (64,40,512)(512,128)=>(64,40,128)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)  # (64,40,128) + (64,40,128)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "#     print(\"inputs.shape=\",inputs.shape)  # (None,None)\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\") # (None,1,1,None)\n",
    "#     print(\"padding_mask.shape=\",padding_mask.shape)\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃                                          # (N,T)\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)   # (9000,128) => (N,T,D)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))              # (64,40,128)\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)      # (64,40,128)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 인코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "          dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "      )([outputs, padding_mask])\n",
    "#         print('outputs.shape=',outputs.shape)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더의 테스트\n",
    "\n",
    "# 인코더의 입력\n",
    "x = tf.constant(np.arange(64*40).reshape(64,40))  # (N,T)\n",
    "print(x.shape)\n",
    "\n",
    "# 인코더의 패딩 마스크\n",
    "enc_padding_mask = tf.keras.layers.Lambda(\n",
    "    create_padding_mask, output_shape=(1, 1, 40),\n",
    "    name='enc_padding_mask')(x)\n",
    "\n",
    "print(enc_padding_mask.shape)\n",
    "\n",
    "# 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "enc_outputs = encoder(vocab_size=9000, num_layers=2, dff=512,\n",
    "    d_model=128, num_heads=4, dropout=0.2,)(inputs=[x, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "print(enc_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=5\n",
    "a = tf.ones((seq_len, seq_len))\n",
    "print(a)\n",
    "print(tf.linalg.band_part(a, -1, 0))\n",
    "print(1-tf.linalg.band_part(a, -1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    print(seq_len)  # 5\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n",
    "#     return look_ahead_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[5, 4, 1, 0, 0]])))  # (N,T) => (1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "        })\n",
    "\n",
    "    # 잔차 연결과 층 정규화\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "            'mask': padding_mask # 패딩 마스크\n",
    "        })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                  d_model, num_heads, dropout,\n",
    "                  name=\"transformer\"):\n",
    "\n",
    "    # 인코더의 입력\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 디코더의 입력\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더의 패딩 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 디코더의 패딩 마스크(두번째 서브층)\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 다음 단어 예측을 위한 출력층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_transformer = transformer(\n",
    "    vocab_size = 9000,\n",
    "    num_layers = 4,\n",
    "    dff = 512,\n",
    "    d_model = 128,\n",
    "    num_heads = 4,\n",
    "    dropout = 0.3,\n",
    "    name=\"small_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    small_transformer, to_file='small_transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "# Text(0.5, 0, 'Train Step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow_datasets 처음 설치 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow_datasets 업그레이드 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --user --upgrade tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfds.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\", filename=\"ChatBotData.csv\")\n",
    "train_data = pd.read_csv('ChatBotData.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('챗봇 샘플의 개수 :', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = re.sub(r\"([?.!,])\", r\" \\1 \", \"   12시 땡!    \")\n",
    "sentence = sentence.strip()\n",
    "print(\"[%s]\"%sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)\n",
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])\n",
    "print(len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더를 사용하여 질문, 답변 데이터로부터 단어 집합(Vocabulary) 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)\n",
    "print(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
    "print(questions[20])\n",
    "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
    "# 임의의 입력 문장을 sample_string에 저장\n",
    "sample_string = questions[20]\n",
    "\n",
    "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "#     print(sentence1)\n",
    "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "\n",
    "    tokenized_inputs.append(sentence1)\n",
    "    tokenized_outputs.append(sentence2)\n",
    "\n",
    "  # 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "  print(tokenized_inputs[0])\n",
    "\n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)\n",
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"날씨가 좋넹.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"고민이 있어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"너무 화가나\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"카페갈래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"게임하고싶당\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"게임하자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
