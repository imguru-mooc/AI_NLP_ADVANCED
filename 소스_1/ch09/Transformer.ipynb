{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.\n",
      " 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49.], shape=(50,), dtype=float32)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.\n",
      " 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49.]\n",
      "(50,)\n",
      "(50, 1)\n",
      "tf.Tensor(\n",
      "[[ 0.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [10.]\n",
      " [11.]\n",
      " [12.]\n",
      " [13.]\n",
      " [14.]\n",
      " [15.]\n",
      " [16.]\n",
      " [17.]\n",
      " [18.]\n",
      " [19.]\n",
      " [20.]\n",
      " [21.]\n",
      " [22.]\n",
      " [23.]\n",
      " [24.]\n",
      " [25.]\n",
      " [26.]\n",
      " [27.]\n",
      " [28.]\n",
      " [29.]\n",
      " [30.]\n",
      " [31.]\n",
      " [32.]\n",
      " [33.]\n",
      " [34.]\n",
      " [35.]\n",
      " [36.]\n",
      " [37.]\n",
      " [38.]\n",
      " [39.]\n",
      " [40.]\n",
      " [41.]\n",
      " [42.]\n",
      " [43.]\n",
      " [44.]\n",
      " [45.]\n",
      " [46.]\n",
      " [47.]\n",
      " [48.]\n",
      " [49.]], shape=(50, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "position=50\n",
    "a = tf.range(position, dtype=tf.float32)\n",
    "print(a)\n",
    "print(a.numpy())\n",
    "print(a.shape)\n",
    "\n",
    "a = tf.range(position, dtype=tf.float32)[:, tf.newaxis]\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n",
      "(1, 128)\n",
      "tf.Tensor(\n",
      "[[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "   14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "   28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "   42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "   56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "   70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "   84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "   98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      "  112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
      "  126. 127.]], shape=(1, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "d_model = 128\n",
    "i = tf.range(d_model, dtype=tf.float32)\n",
    "print(i.shape)\n",
    "i = i[tf.newaxis, :]\n",
    "print(i.shape)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "# print(angles.shape)\n",
    "# print(angles)\n",
    "\n",
    "x = i[0].numpy()\n",
    "# print(x)\n",
    "y = angles[0].numpy()\n",
    "# print(y)\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[[ 3]\n",
      " [ 6]\n",
      " [ 9]\n",
      " [12]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,5).reshape(4,1)\n",
    "b = 3\n",
    "c = a*b  # (4,1)*() => (4,1)(4,1)\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[[ 3]\n",
      " [ 6]\n",
      " [ 9]\n",
      " [12]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,5).reshape(4,1)\n",
    "b = np.array([3])\n",
    "c = a*b  # (4,1)*(1,) => (4,1)*(4,1) => (4,1)\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "[[ 3  6  9]\n",
      " [12 15 18]\n",
      " [21 24 27]\n",
      " [30 33 36]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,13).reshape(4,3)\n",
    "b = np.array([[3],\n",
    "              [3],\n",
    "              [3],\n",
    "              [3]])\n",
    "c = a*b  # (4,3)*(4,1) => (4,3)*(4,3)\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]]\n",
      "[[0 0 0]\n",
      " [1 2 3]\n",
      " [2 4 6]\n",
      " [3 6 9]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,4).reshape(1,3)\n",
    "b = np.array([[0],\n",
    "              [1],\n",
    "              [2],\n",
    "              [3]])\n",
    "c = a*b  # (1,3)*(4,1) => (4,3)(4,3)\n",
    "print(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.89399666, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.sin(90.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.sin(90.*np.pi/180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.841471, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.sin(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "#         print(\"PositionalEncoding.__init__()\", position, d_model)\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "#         print(\"PositionalEncoding.get_angles()\")\n",
    "#         print(position.shape)  # (50,1)\n",
    "#         print(i.shape)         # (1,128)\n",
    "#         print(d_model)         # 128\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "#         print(angles.shape)\n",
    "#         print(angles)\n",
    "        return position * angles    #   (50,1)*(1,128) => (50,128)*(50,128) => (50,128)\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "#         print(\"PositionalEncoding.positional_encoding()\", position, d_model)\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],  # (50,1)\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],          # (1,128)\n",
    "            d_model=d_model)\n",
    "\n",
    "#         print(angle_rads[:10,:10])\n",
    "#         print(angle_rads.shape)  # (50,128)\n",
    "        \n",
    "#         print(angle_rads[:10, 0:11:2])\n",
    "#         print(angle_rads[:, 0::2].shape)\n",
    "        \n",
    "        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "#         print(sines[:10,:10])\n",
    "#         print(sines.shape)\n",
    "        \n",
    "        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "#         print(cosines[:10,:10])\n",
    "#         print(cosines.shape)\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "#         print(pos_encoding.shape)\n",
    "#         print(pos_encoding)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "#         print(pos_encoding.shape)  # (1, 50,128)\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 128)\n",
    "# print(sample_pos_encoding.pos_encoding.shape)     # (1,50,128)\n",
    "                                                   # (N,T,D)\n",
    "                                            # tf.shape(inputs)[1]\n",
    "# print(sample_pos_encoding.pos_encoding[:, :10, :10])\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 128))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(8).reshape(2,2,2)\n",
    "print(x)\n",
    "w = np.ones((2,3))\n",
    "print(w)   \n",
    "out = np.dot(x,w)    # (2,2,2)(2,3)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(12).reshape(2,3,2)\n",
    "print(x)\n",
    "w = np.ones((2,3))\n",
    "print(w)   \n",
    "out = np.dot(w,x)    # (2,3)(2,2,2)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = tf.constant(np.arange(24).reshape(1,2,3,4),dtype=tf.float32)\n",
    "print(query)\n",
    "\n",
    "key = tf.constant(np.ones((1,2,3,4)),dtype=tf.float32)\n",
    "print(key)\n",
    "\n",
    "matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "print(matmul_qk.shape)\n",
    "print(\"matmul_qk=\", matmul_qk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "    # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True) # (1,4,4,32)(1,4,32,4) => (4,32)(32,4)\n",
    "#     print(\"matmul_qk.shape =\", matmul_qk.shape)         # (1,4,4,4)\n",
    "#     print(\"matmul_qk =\", matmul_qk)\n",
    "    # 스케일링\n",
    "    # dk의 루트값으로 나눠준다.\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "#     print(\"depth=\",depth)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "#     print(\"logits=\",logits)\n",
    "\n",
    "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)  # 1 * (-1000000000)  # (1,4,4,4) += (1,1,1,4)\n",
    "        \n",
    "      \n",
    "\n",
    "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "#     print(\"attention_weights=\",attention_weights)  \n",
    "#     print(\"attention_weights.shape =\",attention_weights.shape)  # (1,4,4,4)\n",
    "#     print(\"attention_weights =\",attention_weights)\n",
    "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    output = tf.matmul(attention_weights, value) # (1,4,4,4)(1,4,4,32) => (1,4,4,32)\n",
    "#     print(\"output.shape =\", output.shape) \n",
    "#     print(\"output =\", output) \n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], \n",
    "                      [0, 10, 0], \n",
    "                      [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = tf.keras.layers.Dense(4)  # weight = (?,4)  , bias = (4,)\n",
    "# dir(dense1)\n",
    "print(dense1.weights)\n",
    "x = tf.constant([[1,2,3]])\n",
    "print(x.shape)\n",
    "out = dense1(x)   # (1,3)(3,4)+(4,)\n",
    "print(dense1.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        \n",
    "#         print(\"MultiHeadAttention.__init__()\")\n",
    "        self.num_heads = num_heads     # 4\n",
    "        self.d_model = d_model         # 128\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        # d_model을 num_heads로 나눈 값.\n",
    "        # 논문 기준 : 64\n",
    "        self.depth = d_model // self.num_heads  # 32\n",
    "#         print(\"self.depth=\", self.depth)\n",
    "\n",
    "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)  # (?,128)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "#         print(self.query_dense.weights)\n",
    "        # WO에 해당하는 밀집층 정의\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)  # (128,128)\n",
    "\n",
    "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "#         print(\"split_heads()\")\n",
    "#         print(inputs.shape)\n",
    "        inputs = tf.reshape(                                             # (1,4,128)\n",
    "                                                                         # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))  # (1,4,4,32)\n",
    "                                                                         # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "#         print(inputs.shape)                                            # (1,4,4,32)\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        print(\"batch_size=\", batch_size)\n",
    "\n",
    "        print(query[0,0,:10])\n",
    "        print(key[0,0,:10])        \n",
    "        \n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "        # q : (batch_size, query의 문장 길이, d_model)  =>  (1,4,128)\n",
    "        # k : (batch_size, key의 문장 길이, d_model)\n",
    "        # v : (batch_size, value의 문장 길이, d_model)\n",
    "        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "        query = self.query_dense(query)    # (1,4,128)(128,128) => (1,4,128)\n",
    "        key = self.key_dense(key)          # (1,4,128)(128,128) => (1,4,128)\n",
    "        value = self.value_dense(value)    # (1,4,128)(128,128) => (1,4,128)\n",
    "        \n",
    "        print(self.query_dense.weights)\n",
    "        print(query.shape)\n",
    "        print(key.shape)\n",
    "        print(value.shape)\n",
    "        \n",
    "        print(query[0,0,:10])\n",
    "        print(key[0,0,:10])\n",
    "\n",
    "        # 2. 헤드 나누기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "#         print(query.shape)\n",
    "#         print(key.shape)\n",
    "#         print(value.shape)\n",
    "        \n",
    "\n",
    "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "#         print('scaled_attention.shape=',scaled_attention.shape)\n",
    "        \n",
    "        # 4. 헤드 연결(concatenate)하기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "#         print('concat_attention.shape=',concat_attention.shape)\n",
    "\n",
    "        # 5. WO에 해당하는 밀집층 지나기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        outputs = self.dense(concat_attention)  # (1,4,128)(128,128) => (1,4,128)\n",
    "#         print('outputs.shape=',outputs.shape)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2802379093.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [90]\u001b[1;36m\u001b[0m\n\u001b[1;33m    // 5월 9일은 여기부터\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mha = MultiHeadAttention(128,4)\n",
    "x = tf.constant(np.random.randn(1,4,128))\n",
    "inputs = { 'query':x, 'key':x, 'value':x, 'mask':None }\n",
    "mha(inputs)\n",
    "# 5월 9일은 여기부터\n",
    "# outputs = MultiHeadAttention(128,4)({ 'query':x, 'key':x, 'value':x, 'mask':None })\n",
    "# print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32) # (2,5)\n",
    "    # (batch_size, 1, 1, key의 문장 길이)\n",
    "#     print(mask) #  [[0, 0, 0, 1, 1],\n",
    "                #   [1, 1, 0, 0, 0]]  (2,5)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]  # (2,1,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))  # (1,1,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0],\n",
    "                                       [0, 0, 777, 23, 25]])))  # (2,1,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(np.random.randn(1,4,128))\n",
    "\n",
    "mask = create_padding_mask(tf.constant([[1, 0, 777, 0]]))  # (1,1,1,4)\n",
    "\n",
    "outputs = MultiHeadAttention(128,4)({ 'query':x, 'key':x, 'value':x, 'mask':mask })\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")   # (None,None,128)\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")  # (None,1,1,None)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': padding_mask # 패딩 마스크 사용\n",
    "        })       \n",
    "    \n",
    "#     print('attention.shape=', attention.shape)  # (64,40,128)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "#     print('attention.shape=', attention.shape)  # (64,40,128)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)  # (64,40,128) + (64,40,128)\n",
    "    \n",
    "#     print('attention.shape=', attention.shape)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)  # (64,40,128)(128,512)=>(64,40,512)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)  # (64,40,512)(512,128)=>(64,40,128)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)  # (64,40,128) + (64,40,128)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "#     print(\"inputs.shape=\",inputs.shape)  # (None,None)\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\") # (None,1,1,None)\n",
    "#     print(\"padding_mask.shape=\",padding_mask.shape)\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃                                          # (N,T)\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)   # (9000,128) => (N,T,D)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))              # (64,40,128)\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)      # (64,40,128)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 인코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "          dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "      )([outputs, padding_mask])\n",
    "#         print('outputs.shape=',outputs.shape)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더의 테스트\n",
    "\n",
    "# 인코더의 입력\n",
    "x = tf.constant(np.arange(64*40).reshape(64,40))\n",
    "print(x.shape)\n",
    "\n",
    "# 인코더의 패딩 마스크\n",
    "enc_padding_mask = tf.keras.layers.Lambda(\n",
    "    create_padding_mask, output_shape=(1, 1, 40),\n",
    "    name='enc_padding_mask')(x)\n",
    "\n",
    "print(enc_padding_mask.shape)\n",
    "\n",
    "# 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "enc_outputs = encoder(vocab_size=9000, num_layers=2, dff=512,\n",
    "    d_model=128, num_heads=4, dropout=0.2,)(inputs=[x, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "print(enc_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=5\n",
    "a = tf.ones((seq_len, seq_len))\n",
    "print(a)\n",
    "print(tf.linalg.band_part(a, -1, 0))\n",
    "print(1-tf.linalg.band_part(a, -1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    print(seq_len)  # 5\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n",
    "#     return look_ahead_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[5, 4, 1, 2, 3]])))  # (N,T) => (1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "        })\n",
    "\n",
    "    # 잔차 연결과 층 정규화\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "            'mask': padding_mask # 패딩 마스크\n",
    "        })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                  d_model, num_heads, dropout,\n",
    "                  name=\"transformer\"):\n",
    "\n",
    "    # 인코더의 입력\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 디코더의 입력\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더의 패딩 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 디코더의 패딩 마스크(두번째 서브층)\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 다음 단어 예측을 위한 출력층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_transformer = transformer(\n",
    "    vocab_size = 9000,\n",
    "    num_layers = 4,\n",
    "    dff = 512,\n",
    "    d_model = 128,\n",
    "    num_heads = 4,\n",
    "    dropout = 0.3,\n",
    "    name=\"small_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    small_transformer, to_file='small_transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "# Text(0.5, 0, 'Train Step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow_datasets 처음 설치 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow_datasets 업그레이드 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --user --upgrade tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfds.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\", filename=\"ChatBotData.csv\")\n",
    "train_data = pd.read_csv('ChatBotData.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('챗봇 샘플의 개수 :', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = re.sub(r\"([?.!,])\", r\" \\1 \", \"   12시 땡!   \")\n",
    "sentence = sentence.strip()\n",
    "print(\"[%s]\"%sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)\n",
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])\n",
    "print(len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더를 사용하여 질문, 답변 데이터로부터 단어 집합(Vocabulary) 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
    "print(questions[20])\n",
    "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
    "# 임의의 입력 문장을 sample_string에 저장\n",
    "sample_string = questions[20]\n",
    "\n",
    "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "#     print(sentence1)\n",
    "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "\n",
    "    tokenized_inputs.append(sentence1)\n",
    "    tokenized_outputs.append(sentence2)\n",
    "\n",
    "  # 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "  print(tokenized_inputs[0])\n",
    "\n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)\n",
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"날씨가 좋넹.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"고민이 있어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"너무 화가나\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"카페갈래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"게임하고싶당\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(\"게임하자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
